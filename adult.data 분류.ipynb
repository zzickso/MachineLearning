{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인구 조사 자료를 바탕으로 소득이 $ 50,000 / 년을 초과하는지 예측합니다\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "names=['age','workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country','target']\n",
    "df_adult = pd.read_csv('adult.data.csv',names=names)\n",
    "df_adult.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age:                나이\n",
    "- workclass:          노동 계급 \n",
    "- fnlwgt:             ??\n",
    "- education:          교육\n",
    "- education-num:      교육 수\n",
    "- marital-status:     결혼 상태\n",
    "- occupation:         직업\n",
    "- relationship:       가족내에서 관계\n",
    "- race:               인종\n",
    "- sex:                성별\n",
    "- capital-gain:       자본이득 \n",
    "- capital-loss:       자본손실\n",
    "- hours-per-week:     주당 근로시간\n",
    "- native-country:     출신 국가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.shape  # 데이터 모양 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  target          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_adult.info() # 데이터 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K    24720\n",
      " >50K      7841\n",
      "Name: target, dtype: int64\n",
      "\n",
      "24.08\n"
     ]
    }
   ],
   "source": [
    "#5만 달러 넘는 비율 찾기\n",
    "print(df_adult['target'].value_counts())   \n",
    "\n",
    "print()\n",
    "print(\"%.2f\" %(7841/32561*100))\n",
    "# 5만 달러 넘는 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                  0\n",
       "workclass         1836\n",
       "fnlwgt               0\n",
       "education            0\n",
       "education-num        0\n",
       "marital-status       0\n",
       "occupation        1843\n",
       "relationship         0\n",
       "race                 0\n",
       "sex                  0\n",
       "capital-gain         0\n",
       "capital-loss         0\n",
       "hours-per-week       0\n",
       "native-country     583\n",
       "target               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace()로 데이터 값 중에 ? 값 => nan 으로 바꿔주기\n",
    "df_adult.replace(' ?',np.nan, inplace=True)\n",
    "df_adult.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education-num     0\n",
       "marital-status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital-gain      0\n",
       "capital-loss      0\n",
       "hours-per-week    0\n",
       "native-country    0\n",
       "target            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropna() 로 nan 값 없애주기\n",
    "df_adult=df_adult.dropna(axis=0)\n",
    "df_adult.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스를 새로 배정\n",
    "df_adult=df_adult.reset_index(inplace=False,drop=True)\n",
    "df_adult.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fnlwgt 컬럼은 필요없다고 판단하여 제거\n",
    "# marital-status, relationship 별로 상관업는 거 같은데 영향력이 커서   제거하고 해보기로함.\n",
    "\n",
    "df_adult.drop(['fnlwgt','marital-status','relationship'],axis=1,inplace=True)\n",
    "df_adult.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  education  education-num  occupation  race  sex  \\\n",
       "0   39          5          9             13           0     4    1   \n",
       "1   50          4          9             13           3     4    1   \n",
       "2   38          2         11              9           5     4    1   \n",
       "3   53          2          1              7           5     2    1   \n",
       "4   28          2          9             13           9     2    0   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40              38       0  \n",
       "1             0             0              13              38       0  \n",
       "2             0             0              40              38       0  \n",
       "3             0             0              40              38       0  \n",
       "4             0             0              40               4       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 레이블 인코더 사용해서 문자열=> 숫자\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "col=names=['workclass','education','occupation',  'race', 'sex', 'native-country','target']\n",
    "le=LabelEncoder()\n",
    "for k in col:\n",
    "    df_adult[k]=le.fit_transform(df_adult[k])\n",
    "\n",
    "\n",
    "df_adult.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 비율 맞춰주기 위해  StandardScaler 적용\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "Xdf=df_adult.loc[:,'age':'native-country']\n",
    "ydf=df_adult.loc[:,'target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xdf)\n",
    "adult_scaled = scaler.transform(Xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-1.479055</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>1.887682</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.734545</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.264924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>0.174763</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.238206</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>-2.448375</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.238206</td>\n",
       "      <td>-2.011035</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.754473</td>\n",
       "      <td>-2.011035</td>\n",
       "      <td>-1.443405</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-5.304034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass  education  education-num  occupation      race  \\\n",
       "0  0.042796   2.936000  -0.349865       1.128918   -1.479055  0.385048   \n",
       "1  0.880288   1.887682  -0.349865       1.128918   -0.734545  0.385048   \n",
       "2 -0.033340  -0.208955   0.174763      -0.439738   -0.238206  0.385048   \n",
       "3  1.108695  -0.208955  -2.448375      -1.224066   -0.238206 -2.011035   \n",
       "4 -0.794697  -0.208955  -0.349865       1.128918    0.754473 -2.011035   \n",
       "\n",
       "        sex  capital-gain  capital-loss  hours-per-week  native-country  \n",
       "0  0.692806      0.146092     -0.218586       -0.077734        0.264924  \n",
       "1  0.692806     -0.147445     -0.218586       -2.331531        0.264924  \n",
       "2  0.692806     -0.147445     -0.218586       -0.077734        0.264924  \n",
       "3  0.692806     -0.147445     -0.218586       -0.077734        0.264924  \n",
       "4 -1.443405     -0.147445     -0.218586       -0.077734       -5.304034  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=['age','workclass',  'education', 'education-num', 'occupation',  'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "df_adult=pd.DataFrame(data=adult_scaled,columns=names)\n",
    "df_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042796</td>\n",
       "      <td>2.936000</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-1.479055</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>0.146092</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.880288</td>\n",
       "      <td>1.887682</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>-0.734545</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-2.331531</td>\n",
       "      <td>0.264924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.033340</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>0.174763</td>\n",
       "      <td>-0.439738</td>\n",
       "      <td>-0.238206</td>\n",
       "      <td>0.385048</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.108695</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>-2.448375</td>\n",
       "      <td>-1.224066</td>\n",
       "      <td>-0.238206</td>\n",
       "      <td>-2.011035</td>\n",
       "      <td>0.692806</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>0.264924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.794697</td>\n",
       "      <td>-0.208955</td>\n",
       "      <td>-0.349865</td>\n",
       "      <td>1.128918</td>\n",
       "      <td>0.754473</td>\n",
       "      <td>-2.011035</td>\n",
       "      <td>-1.443405</td>\n",
       "      <td>-0.147445</td>\n",
       "      <td>-0.218586</td>\n",
       "      <td>-0.077734</td>\n",
       "      <td>-5.304034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass  education  education-num  occupation      race  \\\n",
       "0  0.042796   2.936000  -0.349865       1.128918   -1.479055  0.385048   \n",
       "1  0.880288   1.887682  -0.349865       1.128918   -0.734545  0.385048   \n",
       "2 -0.033340  -0.208955   0.174763      -0.439738   -0.238206  0.385048   \n",
       "3  1.108695  -0.208955  -2.448375      -1.224066   -0.238206 -2.011035   \n",
       "4 -0.794697  -0.208955  -0.349865       1.128918    0.754473 -2.011035   \n",
       "\n",
       "        sex  capital-gain  capital-loss  hours-per-week  native-country  \\\n",
       "0  0.692806      0.146092     -0.218586       -0.077734        0.264924   \n",
       "1  0.692806     -0.147445     -0.218586       -2.331531        0.264924   \n",
       "2  0.692806     -0.147445     -0.218586       -0.077734        0.264924   \n",
       "3  0.692806     -0.147445     -0.218586       -0.077734        0.264924   \n",
       "4 -1.443405     -0.147445     -0.218586       -0.077734       -5.304034   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult['target']=ydf\n",
    "df_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_adult.loc[:,'age':'native-country']\n",
    "y=df_adult.loc[:,'target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# 배웠던 평가지표를 구현하는 함수\n",
    "def get_clf_eval(y_test , pred):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.841\n",
      "테스트 세트 정확도: 0.809\n",
      "\n",
      "오차 행렬\n",
      "[[5187  452]\n",
      " [ 990  912]]\n",
      "정확도: 0.8088, 정밀도: 0.6686, 재현율: 0.4795,    F1: 0.5585, AUC:0.6997\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=13)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.831\n",
      "테스트 세트 정확도: 0.821\n",
      "\n",
      "오차 행렬\n",
      "[[5369  270]\n",
      " [1079  823]]\n",
      "정확도: 0.8211, 정밀도: 0.7530, 재현율: 0.4327,    F1: 0.5496, AUC:0.6924\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "clf=svm.SVC(gamma=0.01,C=50.)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 점수: 0.821\n",
      "테스트 세트 점수: 0.812\n",
      "\n",
      "오차 행렬\n",
      "[[5306  333]\n",
      " [1086  816]]\n",
      "정확도: 0.8118, 정밀도: 0.7102, 재현율: 0.4290,    F1: 0.5349, AUC:0.6850\n"
     ]
    }
   ],
   "source": [
    "#로지스틱 회귀\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(C=0.1,max_iter=5000).fit(X_train, y_train)\n",
    "print(\"훈련 세트 점수: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 점수: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.845\n",
      "테스트 세트 정확도: 0.831\n",
      "\n",
      "오차 행렬\n",
      "[[5412  227]\n",
      " [1048  854]]\n",
      "정확도: 0.8309, 정밀도: 0.7900, 재현율: 0.4490,    F1: 0.5726, AUC:0.7044\n"
     ]
    }
   ],
   "source": [
    "#결정트리분류기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf=DecisionTreeClassifier(max_depth=8)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.178 0.002 0.001 0.219 0.006 0.002 0.087 0.365 0.098 0.041 0.001]\n",
      "age : 0.178\n",
      "workclass : 0.002\n",
      "education : 0.001\n",
      "education-num : 0.219\n",
      "occupation : 0.006\n",
      "race : 0.002\n",
      "sex : 0.087\n",
      "capital-gain : 0.365\n",
      "capital-loss : 0.098\n",
      "hours-per-week : 0.041\n",
      "native-country : 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# feature importance 추출\n",
    "print(\"Feature importances:\\n{0}\".format(np.round(clf.feature_importances_,\n",
    "3)))\n",
    "# feature별 importance 매핑\n",
    "for name, value in zip(names , clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "# feature importance를 column 별로 시각화 하기\n",
    "sns.barplot(x=clf.feature_importances_ , y=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:\n",
      " {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "최고 예측 정확도: 0.8421\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 최적의 파라메타 찾기 GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,300],\n",
    "    'max_depth' : [10, 12,14,16], \n",
    "    'min_samples_leaf' : [4, 6, 8,10],\n",
    "    'min_samples_split' : [8,10,12,14]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "grid_cv = GridSearchCV(clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.849\n",
      "테스트 세트 정확도: 0.836\n",
      "\n",
      "오차 행렬\n",
      "[[5394  245]\n",
      " [ 995  907]]\n",
      "정확도: 0.8356, 정밀도: 0.7873, 재현율: 0.4769,    F1: 0.5940, AUC:0.7167\n"
     ]
    }
   ],
   "source": [
    "#랜덤포레스트\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=300)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.181 0.014 0.033 0.201 0.04  0.006 0.081 0.272 0.08  0.089 0.004]\n",
      "age : 0.181\n",
      "workclass : 0.014\n",
      "education : 0.033\n",
      "education-num : 0.201\n",
      "occupation : 0.040\n",
      "race : 0.006\n",
      "sex : 0.081\n",
      "capital-gain : 0.272\n",
      "capital-loss : 0.080\n",
      "hours-per-week : 0.089\n",
      "native-country : 0.004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "# feature importance 추출\n",
    "print(\"Feature importances:\\n{0}\".format(np.round(clf.feature_importances_,\n",
    "3)))\n",
    "# feature별 importance 매핑\n",
    "for name, value in zip(names , clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "# feature importance를 column 별로 시각화 하기\n",
    "sns.barplot(x=clf.feature_importances_ , y=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.846\n",
      "테스트 세트 정확도: 0.837\n",
      "\n",
      "오차 행렬\n",
      "[[5323  316]\n",
      " [ 911  991]]\n",
      "정확도: 0.8373, 정밀도: 0.7582, 재현율: 0.5210,    F1: 0.6176, AUC:0.7325\n"
     ]
    }
   ],
   "source": [
    "#adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf=AdaBoostClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 세트 정확도: 0.867\n",
      "테스트 세트 정확도: 0.847\n",
      "\n",
      "오차 행렬\n",
      "[[5338  301]\n",
      " [ 851 1051]]\n",
      "정확도: 0.8472, 정밀도: 0.7774, 재현율: 0.5526,    F1: 0.6460, AUC:0.7496\n"
     ]
    }
   ],
   "source": [
    "#GBM\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(\"훈련 세트 정확도: {:.3f}\".format(clf.score(X_train, y_train)))\n",
    "print(\"테스트 세트 정확도: {:.3f}\".format(clf.score(X_test, y_test)))\n",
    "print()\n",
    "pred=clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: scipy in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from xgboost) (1.5.4)\n",
      "Requirement already satisfied: numpy in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from xgboost) (1.18.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'e:\\모든파일\\프로그래밍\\파이썬\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.64996\n",
      "[1]\tvalidation_0-logloss:0.61476\n",
      "[2]\tvalidation_0-logloss:0.58558\n",
      "[3]\tvalidation_0-logloss:0.56124\n",
      "[4]\tvalidation_0-logloss:0.54033\n",
      "[5]\tvalidation_0-logloss:0.52272\n",
      "[6]\tvalidation_0-logloss:0.50743\n",
      "[7]\tvalidation_0-logloss:0.49361\n",
      "[8]\tvalidation_0-logloss:0.48197\n",
      "[9]\tvalidation_0-logloss:0.47088\n",
      "[10]\tvalidation_0-logloss:0.46156\n",
      "[11]\tvalidation_0-logloss:0.45375\n",
      "[12]\tvalidation_0-logloss:0.44566\n",
      "[13]\tvalidation_0-logloss:0.43935\n",
      "[14]\tvalidation_0-logloss:0.43309\n",
      "[15]\tvalidation_0-logloss:0.42786\n",
      "[16]\tvalidation_0-logloss:0.42293\n",
      "[17]\tvalidation_0-logloss:0.41887\n",
      "[18]\tvalidation_0-logloss:0.41510\n",
      "[19]\tvalidation_0-logloss:0.41167\n",
      "[20]\tvalidation_0-logloss:0.40824\n",
      "[21]\tvalidation_0-logloss:0.40531\n",
      "[22]\tvalidation_0-logloss:0.40268\n",
      "[23]\tvalidation_0-logloss:0.40010\n",
      "[24]\tvalidation_0-logloss:0.39799\n",
      "[25]\tvalidation_0-logloss:0.39589\n",
      "[26]\tvalidation_0-logloss:0.39386\n",
      "[27]\tvalidation_0-logloss:0.39186\n",
      "[28]\tvalidation_0-logloss:0.38984\n",
      "[29]\tvalidation_0-logloss:0.38776\n",
      "[30]\tvalidation_0-logloss:0.38630\n",
      "[31]\tvalidation_0-logloss:0.38503\n",
      "[32]\tvalidation_0-logloss:0.38386\n",
      "[33]\tvalidation_0-logloss:0.38271\n",
      "[34]\tvalidation_0-logloss:0.38133\n",
      "[35]\tvalidation_0-logloss:0.38018\n",
      "[36]\tvalidation_0-logloss:0.37832\n",
      "[37]\tvalidation_0-logloss:0.37737\n",
      "[38]\tvalidation_0-logloss:0.37610\n",
      "[39]\tvalidation_0-logloss:0.37535\n",
      "[40]\tvalidation_0-logloss:0.37435\n",
      "[41]\tvalidation_0-logloss:0.37368\n",
      "[42]\tvalidation_0-logloss:0.37248\n",
      "[43]\tvalidation_0-logloss:0.37170\n",
      "[44]\tvalidation_0-logloss:0.37097\n",
      "[45]\tvalidation_0-logloss:0.37035\n",
      "[46]\tvalidation_0-logloss:0.36972\n",
      "[47]\tvalidation_0-logloss:0.36816\n",
      "[48]\tvalidation_0-logloss:0.36698\n",
      "[49]\tvalidation_0-logloss:0.36671\n",
      "[50]\tvalidation_0-logloss:0.36620\n",
      "[51]\tvalidation_0-logloss:0.36570\n",
      "[52]\tvalidation_0-logloss:0.36524\n",
      "[53]\tvalidation_0-logloss:0.36394\n",
      "[54]\tvalidation_0-logloss:0.36362\n",
      "[55]\tvalidation_0-logloss:0.36331\n",
      "[56]\tvalidation_0-logloss:0.36286\n",
      "[57]\tvalidation_0-logloss:0.36259\n",
      "[58]\tvalidation_0-logloss:0.36165\n",
      "[59]\tvalidation_0-logloss:0.36077\n",
      "[60]\tvalidation_0-logloss:0.36062\n",
      "[61]\tvalidation_0-logloss:0.36028\n",
      "[62]\tvalidation_0-logloss:0.35993\n",
      "[63]\tvalidation_0-logloss:0.35966\n",
      "[64]\tvalidation_0-logloss:0.35892\n",
      "[65]\tvalidation_0-logloss:0.35863\n",
      "[66]\tvalidation_0-logloss:0.35829\n",
      "[67]\tvalidation_0-logloss:0.35797\n",
      "[68]\tvalidation_0-logloss:0.35789\n",
      "[69]\tvalidation_0-logloss:0.35728\n",
      "[70]\tvalidation_0-logloss:0.35656\n",
      "[71]\tvalidation_0-logloss:0.35644\n",
      "[72]\tvalidation_0-logloss:0.35615\n",
      "[73]\tvalidation_0-logloss:0.35595\n",
      "[74]\tvalidation_0-logloss:0.35564\n",
      "[75]\tvalidation_0-logloss:0.35547\n",
      "[76]\tvalidation_0-logloss:0.35524\n",
      "[77]\tvalidation_0-logloss:0.35516\n",
      "[78]\tvalidation_0-logloss:0.35509\n",
      "[79]\tvalidation_0-logloss:0.35477\n",
      "[80]\tvalidation_0-logloss:0.35468\n",
      "[81]\tvalidation_0-logloss:0.35454\n",
      "[82]\tvalidation_0-logloss:0.35431\n",
      "[83]\tvalidation_0-logloss:0.35423\n",
      "[84]\tvalidation_0-logloss:0.35396\n",
      "[85]\tvalidation_0-logloss:0.35383\n",
      "[86]\tvalidation_0-logloss:0.35350\n",
      "[87]\tvalidation_0-logloss:0.35335\n",
      "[88]\tvalidation_0-logloss:0.35290\n",
      "[89]\tvalidation_0-logloss:0.35268\n",
      "[90]\tvalidation_0-logloss:0.35255\n",
      "[91]\tvalidation_0-logloss:0.35248\n",
      "[92]\tvalidation_0-logloss:0.35244\n",
      "[93]\tvalidation_0-logloss:0.35220\n",
      "[94]\tvalidation_0-logloss:0.35201\n",
      "[95]\tvalidation_0-logloss:0.35163\n",
      "[96]\tvalidation_0-logloss:0.35160\n",
      "[97]\tvalidation_0-logloss:0.35147\n",
      "[98]\tvalidation_0-logloss:0.35092\n",
      "[99]\tvalidation_0-logloss:0.35072\n",
      "[100]\tvalidation_0-logloss:0.35050\n",
      "[101]\tvalidation_0-logloss:0.35048\n",
      "[102]\tvalidation_0-logloss:0.35020\n",
      "[103]\tvalidation_0-logloss:0.35001\n",
      "[104]\tvalidation_0-logloss:0.34987\n",
      "[105]\tvalidation_0-logloss:0.34990\n",
      "[106]\tvalidation_0-logloss:0.34978\n",
      "[107]\tvalidation_0-logloss:0.34974\n",
      "[108]\tvalidation_0-logloss:0.34928\n",
      "[109]\tvalidation_0-logloss:0.34926\n",
      "[110]\tvalidation_0-logloss:0.34909\n",
      "[111]\tvalidation_0-logloss:0.34900\n",
      "[112]\tvalidation_0-logloss:0.34854\n",
      "[113]\tvalidation_0-logloss:0.34802\n",
      "[114]\tvalidation_0-logloss:0.34776\n",
      "[115]\tvalidation_0-logloss:0.34772\n",
      "[116]\tvalidation_0-logloss:0.34756\n",
      "[117]\tvalidation_0-logloss:0.34726\n",
      "[118]\tvalidation_0-logloss:0.34693\n",
      "[119]\tvalidation_0-logloss:0.34669\n",
      "[120]\tvalidation_0-logloss:0.34658\n",
      "[121]\tvalidation_0-logloss:0.34658\n",
      "[122]\tvalidation_0-logloss:0.34646\n",
      "[123]\tvalidation_0-logloss:0.34608\n",
      "[124]\tvalidation_0-logloss:0.34588\n",
      "[125]\tvalidation_0-logloss:0.34556\n",
      "[126]\tvalidation_0-logloss:0.34534\n",
      "[127]\tvalidation_0-logloss:0.34521\n",
      "[128]\tvalidation_0-logloss:0.34521\n",
      "[129]\tvalidation_0-logloss:0.34506\n",
      "[130]\tvalidation_0-logloss:0.34505\n",
      "[131]\tvalidation_0-logloss:0.34480\n",
      "[132]\tvalidation_0-logloss:0.34479\n",
      "[133]\tvalidation_0-logloss:0.34456\n",
      "[134]\tvalidation_0-logloss:0.34434\n",
      "[135]\tvalidation_0-logloss:0.34418\n",
      "[136]\tvalidation_0-logloss:0.34407\n",
      "[137]\tvalidation_0-logloss:0.34409\n",
      "[138]\tvalidation_0-logloss:0.34409\n",
      "[139]\tvalidation_0-logloss:0.34399\n",
      "[140]\tvalidation_0-logloss:0.34397\n",
      "[141]\tvalidation_0-logloss:0.34383\n",
      "[142]\tvalidation_0-logloss:0.34364\n",
      "[143]\tvalidation_0-logloss:0.34347\n",
      "[144]\tvalidation_0-logloss:0.34336\n",
      "[145]\tvalidation_0-logloss:0.34336\n",
      "[146]\tvalidation_0-logloss:0.34332\n",
      "[147]\tvalidation_0-logloss:0.34334\n",
      "[148]\tvalidation_0-logloss:0.34336\n",
      "[149]\tvalidation_0-logloss:0.34324\n",
      "[150]\tvalidation_0-logloss:0.34309\n",
      "[151]\tvalidation_0-logloss:0.34303\n",
      "[152]\tvalidation_0-logloss:0.34265\n",
      "[153]\tvalidation_0-logloss:0.34251\n",
      "[154]\tvalidation_0-logloss:0.34252\n",
      "[155]\tvalidation_0-logloss:0.34243\n",
      "[156]\tvalidation_0-logloss:0.34226\n",
      "[157]\tvalidation_0-logloss:0.34195\n",
      "[158]\tvalidation_0-logloss:0.34195\n",
      "[159]\tvalidation_0-logloss:0.34192\n",
      "[160]\tvalidation_0-logloss:0.34193\n",
      "[161]\tvalidation_0-logloss:0.34172\n",
      "[162]\tvalidation_0-logloss:0.34167\n",
      "[163]\tvalidation_0-logloss:0.34171\n",
      "[164]\tvalidation_0-logloss:0.34163\n",
      "[165]\tvalidation_0-logloss:0.34144\n",
      "[166]\tvalidation_0-logloss:0.34146\n",
      "[167]\tvalidation_0-logloss:0.34126\n",
      "[168]\tvalidation_0-logloss:0.34119\n",
      "[169]\tvalidation_0-logloss:0.34109\n",
      "[170]\tvalidation_0-logloss:0.34097\n",
      "[171]\tvalidation_0-logloss:0.34093\n",
      "[172]\tvalidation_0-logloss:0.34084\n",
      "[173]\tvalidation_0-logloss:0.34076\n",
      "[174]\tvalidation_0-logloss:0.34076\n",
      "[175]\tvalidation_0-logloss:0.34074\n",
      "[176]\tvalidation_0-logloss:0.34064\n",
      "[177]\tvalidation_0-logloss:0.34046\n",
      "[178]\tvalidation_0-logloss:0.34025\n",
      "[179]\tvalidation_0-logloss:0.34025\n",
      "[180]\tvalidation_0-logloss:0.34017\n",
      "[181]\tvalidation_0-logloss:0.34015\n",
      "[182]\tvalidation_0-logloss:0.34001\n",
      "[183]\tvalidation_0-logloss:0.34005\n",
      "[184]\tvalidation_0-logloss:0.34006\n",
      "[185]\tvalidation_0-logloss:0.33999\n",
      "[186]\tvalidation_0-logloss:0.33997\n",
      "[187]\tvalidation_0-logloss:0.33985\n",
      "[188]\tvalidation_0-logloss:0.33961\n",
      "[189]\tvalidation_0-logloss:0.33953\n",
      "[190]\tvalidation_0-logloss:0.33954\n",
      "[191]\tvalidation_0-logloss:0.33954\n",
      "[192]\tvalidation_0-logloss:0.33947\n",
      "[193]\tvalidation_0-logloss:0.33939\n",
      "[194]\tvalidation_0-logloss:0.33932\n",
      "[195]\tvalidation_0-logloss:0.33935\n",
      "[196]\tvalidation_0-logloss:0.33932\n",
      "[197]\tvalidation_0-logloss:0.33929\n",
      "[198]\tvalidation_0-logloss:0.33924\n",
      "[199]\tvalidation_0-logloss:0.33916\n",
      "[200]\tvalidation_0-logloss:0.33917\n",
      "[201]\tvalidation_0-logloss:0.33899\n",
      "[202]\tvalidation_0-logloss:0.33902\n",
      "[203]\tvalidation_0-logloss:0.33896\n",
      "[204]\tvalidation_0-logloss:0.33881\n",
      "[205]\tvalidation_0-logloss:0.33879\n",
      "[206]\tvalidation_0-logloss:0.33869\n",
      "[207]\tvalidation_0-logloss:0.33865\n",
      "[208]\tvalidation_0-logloss:0.33865\n",
      "[209]\tvalidation_0-logloss:0.33857\n",
      "[210]\tvalidation_0-logloss:0.33855\n",
      "[211]\tvalidation_0-logloss:0.33855\n",
      "[212]\tvalidation_0-logloss:0.33853\n",
      "[213]\tvalidation_0-logloss:0.33841\n",
      "[214]\tvalidation_0-logloss:0.33841\n",
      "[215]\tvalidation_0-logloss:0.33838\n",
      "[216]\tvalidation_0-logloss:0.33835\n",
      "[217]\tvalidation_0-logloss:0.33821\n",
      "[218]\tvalidation_0-logloss:0.33821\n",
      "[219]\tvalidation_0-logloss:0.33812\n",
      "[220]\tvalidation_0-logloss:0.33811\n",
      "[221]\tvalidation_0-logloss:0.33810\n",
      "[222]\tvalidation_0-logloss:0.33802\n",
      "[223]\tvalidation_0-logloss:0.33784\n",
      "[224]\tvalidation_0-logloss:0.33778\n",
      "[225]\tvalidation_0-logloss:0.33777\n",
      "[226]\tvalidation_0-logloss:0.33778\n",
      "[227]\tvalidation_0-logloss:0.33772\n",
      "[228]\tvalidation_0-logloss:0.33760\n",
      "[229]\tvalidation_0-logloss:0.33760\n",
      "[230]\tvalidation_0-logloss:0.33745\n",
      "[231]\tvalidation_0-logloss:0.33732\n",
      "[232]\tvalidation_0-logloss:0.33722\n",
      "[233]\tvalidation_0-logloss:0.33724\n",
      "[234]\tvalidation_0-logloss:0.33723\n",
      "[235]\tvalidation_0-logloss:0.33719\n",
      "[236]\tvalidation_0-logloss:0.33715\n",
      "[237]\tvalidation_0-logloss:0.33716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\tvalidation_0-logloss:0.33714\n",
      "[239]\tvalidation_0-logloss:0.33707\n",
      "[240]\tvalidation_0-logloss:0.33708\n",
      "[241]\tvalidation_0-logloss:0.33707\n",
      "[242]\tvalidation_0-logloss:0.33703\n",
      "[243]\tvalidation_0-logloss:0.33704\n",
      "[244]\tvalidation_0-logloss:0.33696\n",
      "[245]\tvalidation_0-logloss:0.33697\n",
      "[246]\tvalidation_0-logloss:0.33697\n",
      "[247]\tvalidation_0-logloss:0.33697\n",
      "[248]\tvalidation_0-logloss:0.33695\n",
      "[249]\tvalidation_0-logloss:0.33692\n",
      "[250]\tvalidation_0-logloss:0.33685\n",
      "[251]\tvalidation_0-logloss:0.33685\n",
      "[252]\tvalidation_0-logloss:0.33674\n",
      "[253]\tvalidation_0-logloss:0.33674\n",
      "[254]\tvalidation_0-logloss:0.33667\n",
      "[255]\tvalidation_0-logloss:0.33662\n",
      "[256]\tvalidation_0-logloss:0.33664\n",
      "[257]\tvalidation_0-logloss:0.33664\n",
      "[258]\tvalidation_0-logloss:0.33654\n",
      "[259]\tvalidation_0-logloss:0.33646\n",
      "[260]\tvalidation_0-logloss:0.33638\n",
      "[261]\tvalidation_0-logloss:0.33637\n",
      "[262]\tvalidation_0-logloss:0.33636\n",
      "[263]\tvalidation_0-logloss:0.33632\n",
      "[264]\tvalidation_0-logloss:0.33630\n",
      "[265]\tvalidation_0-logloss:0.33626\n",
      "[266]\tvalidation_0-logloss:0.33623\n",
      "[267]\tvalidation_0-logloss:0.33613\n",
      "[268]\tvalidation_0-logloss:0.33613\n",
      "[269]\tvalidation_0-logloss:0.33609\n",
      "[270]\tvalidation_0-logloss:0.33606\n",
      "[271]\tvalidation_0-logloss:0.33603\n",
      "[272]\tvalidation_0-logloss:0.33607\n",
      "[273]\tvalidation_0-logloss:0.33611\n",
      "[274]\tvalidation_0-logloss:0.33612\n",
      "[275]\tvalidation_0-logloss:0.33615\n",
      "[276]\tvalidation_0-logloss:0.33609\n",
      "[277]\tvalidation_0-logloss:0.33608\n",
      "[278]\tvalidation_0-logloss:0.33611\n",
      "[279]\tvalidation_0-logloss:0.33605\n",
      "[280]\tvalidation_0-logloss:0.33607\n",
      "[281]\tvalidation_0-logloss:0.33608\n",
      "[282]\tvalidation_0-logloss:0.33606\n",
      "[283]\tvalidation_0-logloss:0.33607\n",
      "[284]\tvalidation_0-logloss:0.33609\n",
      "[285]\tvalidation_0-logloss:0.33607\n",
      "[286]\tvalidation_0-logloss:0.33604\n",
      "[287]\tvalidation_0-logloss:0.33600\n",
      "[288]\tvalidation_0-logloss:0.33593\n",
      "[289]\tvalidation_0-logloss:0.33591\n",
      "[290]\tvalidation_0-logloss:0.33588\n",
      "[291]\tvalidation_0-logloss:0.33587\n",
      "[292]\tvalidation_0-logloss:0.33587\n",
      "[293]\tvalidation_0-logloss:0.33578\n",
      "[294]\tvalidation_0-logloss:0.33574\n",
      "[295]\tvalidation_0-logloss:0.33577\n",
      "[296]\tvalidation_0-logloss:0.33565\n",
      "[297]\tvalidation_0-logloss:0.33567\n",
      "[298]\tvalidation_0-logloss:0.33567\n",
      "[299]\tvalidation_0-logloss:0.33559\n",
      "[300]\tvalidation_0-logloss:0.33556\n",
      "[301]\tvalidation_0-logloss:0.33554\n",
      "[302]\tvalidation_0-logloss:0.33550\n",
      "[303]\tvalidation_0-logloss:0.33548\n",
      "[304]\tvalidation_0-logloss:0.33545\n",
      "[305]\tvalidation_0-logloss:0.33547\n",
      "[306]\tvalidation_0-logloss:0.33543\n",
      "[307]\tvalidation_0-logloss:0.33536\n",
      "[308]\tvalidation_0-logloss:0.33537\n",
      "[309]\tvalidation_0-logloss:0.33535\n",
      "[310]\tvalidation_0-logloss:0.33533\n",
      "[311]\tvalidation_0-logloss:0.33531\n",
      "[312]\tvalidation_0-logloss:0.33529\n",
      "[313]\tvalidation_0-logloss:0.33529\n",
      "[314]\tvalidation_0-logloss:0.33518\n",
      "[315]\tvalidation_0-logloss:0.33519\n",
      "[316]\tvalidation_0-logloss:0.33518\n",
      "[317]\tvalidation_0-logloss:0.33520\n",
      "[318]\tvalidation_0-logloss:0.33524\n",
      "[319]\tvalidation_0-logloss:0.33514\n",
      "[320]\tvalidation_0-logloss:0.33514\n",
      "[321]\tvalidation_0-logloss:0.33515\n",
      "[322]\tvalidation_0-logloss:0.33509\n",
      "[323]\tvalidation_0-logloss:0.33513\n",
      "[324]\tvalidation_0-logloss:0.33515\n",
      "[325]\tvalidation_0-logloss:0.33504\n",
      "[326]\tvalidation_0-logloss:0.33500\n",
      "[327]\tvalidation_0-logloss:0.33499\n",
      "[328]\tvalidation_0-logloss:0.33493\n",
      "[329]\tvalidation_0-logloss:0.33496\n",
      "[330]\tvalidation_0-logloss:0.33488\n",
      "[331]\tvalidation_0-logloss:0.33485\n",
      "[332]\tvalidation_0-logloss:0.33483\n",
      "[333]\tvalidation_0-logloss:0.33476\n",
      "[334]\tvalidation_0-logloss:0.33473\n",
      "[335]\tvalidation_0-logloss:0.33471\n",
      "[336]\tvalidation_0-logloss:0.33475\n",
      "[337]\tvalidation_0-logloss:0.33474\n",
      "[338]\tvalidation_0-logloss:0.33472\n",
      "[339]\tvalidation_0-logloss:0.33471\n",
      "[340]\tvalidation_0-logloss:0.33469\n",
      "[341]\tvalidation_0-logloss:0.33469\n",
      "[342]\tvalidation_0-logloss:0.33466\n",
      "[343]\tvalidation_0-logloss:0.33466\n",
      "[344]\tvalidation_0-logloss:0.33458\n",
      "[345]\tvalidation_0-logloss:0.33457\n",
      "[346]\tvalidation_0-logloss:0.33459\n",
      "[347]\tvalidation_0-logloss:0.33454\n",
      "[348]\tvalidation_0-logloss:0.33455\n",
      "[349]\tvalidation_0-logloss:0.33457\n",
      "[350]\tvalidation_0-logloss:0.33450\n",
      "[351]\tvalidation_0-logloss:0.33445\n",
      "[352]\tvalidation_0-logloss:0.33448\n",
      "[353]\tvalidation_0-logloss:0.33445\n",
      "[354]\tvalidation_0-logloss:0.33442\n",
      "[355]\tvalidation_0-logloss:0.33435\n",
      "[356]\tvalidation_0-logloss:0.33433\n",
      "[357]\tvalidation_0-logloss:0.33433\n",
      "[358]\tvalidation_0-logloss:0.33426\n",
      "[359]\tvalidation_0-logloss:0.33425\n",
      "[360]\tvalidation_0-logloss:0.33425\n",
      "[361]\tvalidation_0-logloss:0.33427\n",
      "[362]\tvalidation_0-logloss:0.33431\n",
      "[363]\tvalidation_0-logloss:0.33427\n",
      "[364]\tvalidation_0-logloss:0.33420\n",
      "[365]\tvalidation_0-logloss:0.33419\n",
      "[366]\tvalidation_0-logloss:0.33420\n",
      "[367]\tvalidation_0-logloss:0.33422\n",
      "[368]\tvalidation_0-logloss:0.33420\n",
      "[369]\tvalidation_0-logloss:0.33419\n",
      "[370]\tvalidation_0-logloss:0.33415\n",
      "[371]\tvalidation_0-logloss:0.33409\n",
      "[372]\tvalidation_0-logloss:0.33407\n",
      "[373]\tvalidation_0-logloss:0.33404\n",
      "[374]\tvalidation_0-logloss:0.33401\n",
      "[375]\tvalidation_0-logloss:0.33399\n",
      "[376]\tvalidation_0-logloss:0.33398\n",
      "[377]\tvalidation_0-logloss:0.33392\n",
      "[378]\tvalidation_0-logloss:0.33389\n",
      "[379]\tvalidation_0-logloss:0.33389\n",
      "[380]\tvalidation_0-logloss:0.33388\n",
      "[381]\tvalidation_0-logloss:0.33389\n",
      "[382]\tvalidation_0-logloss:0.33390\n",
      "[383]\tvalidation_0-logloss:0.33384\n",
      "[384]\tvalidation_0-logloss:0.33377\n",
      "[385]\tvalidation_0-logloss:0.33376\n",
      "[386]\tvalidation_0-logloss:0.33375\n",
      "[387]\tvalidation_0-logloss:0.33375\n",
      "[388]\tvalidation_0-logloss:0.33376\n",
      "[389]\tvalidation_0-logloss:0.33379\n",
      "[390]\tvalidation_0-logloss:0.33374\n",
      "[391]\tvalidation_0-logloss:0.33372\n",
      "[392]\tvalidation_0-logloss:0.33370\n",
      "[393]\tvalidation_0-logloss:0.33369\n",
      "[394]\tvalidation_0-logloss:0.33374\n",
      "[395]\tvalidation_0-logloss:0.33372\n",
      "[396]\tvalidation_0-logloss:0.33371\n",
      "[397]\tvalidation_0-logloss:0.33372\n",
      "[398]\tvalidation_0-logloss:0.33373\n",
      "[399]\tvalidation_0-logloss:0.33373\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "import xgboost as xgb\n",
    "# 사이킷런 래퍼 XGBoost 클래스인 XGBClassifier 임포트\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "xgb_wrapper.fit(X_train , y_train,  early_stopping_rounds=400,eval_set=evals, eval_metric=\"logloss\",  verbose=True)\n",
    "w_preds = xgb_wrapper.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[5336  303]\n",
      " [ 862 1040]]\n",
      "정확도: 0.8455, 정밀도: 0.7744, 재현율: 0.5468,    F1: 0.6410, AUC:0.7465\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test , w_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:33:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { learning_rete } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-logloss:0.59006\n",
      "[1]\tvalidation_0-logloss:0.52914\n",
      "[2]\tvalidation_0-logloss:0.47338\n",
      "[3]\tvalidation_0-logloss:0.45149\n",
      "[4]\tvalidation_0-logloss:0.42620\n",
      "[5]\tvalidation_0-logloss:0.40571\n",
      "[6]\tvalidation_0-logloss:0.39161\n",
      "[7]\tvalidation_0-logloss:0.38425\n",
      "[8]\tvalidation_0-logloss:0.37777\n",
      "[9]\tvalidation_0-logloss:0.37297\n",
      "[10]\tvalidation_0-logloss:0.36728\n",
      "[11]\tvalidation_0-logloss:0.36463\n",
      "[12]\tvalidation_0-logloss:0.36207\n",
      "[13]\tvalidation_0-logloss:0.35855\n",
      "[14]\tvalidation_0-logloss:0.35616\n",
      "[15]\tvalidation_0-logloss:0.35459\n",
      "[16]\tvalidation_0-logloss:0.35162\n",
      "[17]\tvalidation_0-logloss:0.35103\n",
      "[18]\tvalidation_0-logloss:0.34930\n",
      "[19]\tvalidation_0-logloss:0.34734\n",
      "[20]\tvalidation_0-logloss:0.34659\n",
      "[21]\tvalidation_0-logloss:0.34603\n",
      "[22]\tvalidation_0-logloss:0.34442\n",
      "[23]\tvalidation_0-logloss:0.34419\n",
      "[24]\tvalidation_0-logloss:0.34411\n",
      "[25]\tvalidation_0-logloss:0.34381\n",
      "[26]\tvalidation_0-logloss:0.34291\n",
      "[27]\tvalidation_0-logloss:0.34264\n",
      "[28]\tvalidation_0-logloss:0.34250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages\\xgboost\\sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29]\tvalidation_0-logloss:0.34109\n",
      "[30]\tvalidation_0-logloss:0.34088\n",
      "[31]\tvalidation_0-logloss:0.34019\n",
      "[32]\tvalidation_0-logloss:0.34014\n",
      "[33]\tvalidation_0-logloss:0.33976\n",
      "[34]\tvalidation_0-logloss:0.33954\n",
      "[35]\tvalidation_0-logloss:0.33948\n",
      "[36]\tvalidation_0-logloss:0.33939\n",
      "[37]\tvalidation_0-logloss:0.33906\n",
      "[38]\tvalidation_0-logloss:0.33847\n",
      "[39]\tvalidation_0-logloss:0.33827\n",
      "[40]\tvalidation_0-logloss:0.33721\n",
      "[41]\tvalidation_0-logloss:0.33723\n",
      "[42]\tvalidation_0-logloss:0.33706\n",
      "[43]\tvalidation_0-logloss:0.33675\n",
      "[44]\tvalidation_0-logloss:0.33626\n",
      "[45]\tvalidation_0-logloss:0.33591\n",
      "[46]\tvalidation_0-logloss:0.33561\n",
      "[47]\tvalidation_0-logloss:0.33563\n",
      "[48]\tvalidation_0-logloss:0.33533\n",
      "[49]\tvalidation_0-logloss:0.33504\n",
      "[50]\tvalidation_0-logloss:0.33500\n",
      "[51]\tvalidation_0-logloss:0.33506\n",
      "[52]\tvalidation_0-logloss:0.33465\n",
      "[53]\tvalidation_0-logloss:0.33452\n",
      "[54]\tvalidation_0-logloss:0.33443\n",
      "[55]\tvalidation_0-logloss:0.33447\n",
      "[56]\tvalidation_0-logloss:0.33442\n",
      "[57]\tvalidation_0-logloss:0.33456\n",
      "[58]\tvalidation_0-logloss:0.33479\n",
      "[59]\tvalidation_0-logloss:0.33494\n",
      "[60]\tvalidation_0-logloss:0.33455\n",
      "[61]\tvalidation_0-logloss:0.33466\n",
      "[62]\tvalidation_0-logloss:0.33477\n",
      "[63]\tvalidation_0-logloss:0.33440\n",
      "[64]\tvalidation_0-logloss:0.33448\n",
      "[65]\tvalidation_0-logloss:0.33431\n",
      "[66]\tvalidation_0-logloss:0.33410\n",
      "[67]\tvalidation_0-logloss:0.33392\n",
      "[68]\tvalidation_0-logloss:0.33370\n",
      "[69]\tvalidation_0-logloss:0.33360\n",
      "[70]\tvalidation_0-logloss:0.33364\n",
      "[71]\tvalidation_0-logloss:0.33394\n",
      "[72]\tvalidation_0-logloss:0.33398\n",
      "[73]\tvalidation_0-logloss:0.33386\n",
      "[74]\tvalidation_0-logloss:0.33390\n",
      "[75]\tvalidation_0-logloss:0.33385\n",
      "[76]\tvalidation_0-logloss:0.33391\n",
      "[77]\tvalidation_0-logloss:0.33378\n",
      "[78]\tvalidation_0-logloss:0.33411\n",
      "[79]\tvalidation_0-logloss:0.33400\n",
      "[80]\tvalidation_0-logloss:0.33403\n",
      "[81]\tvalidation_0-logloss:0.33404\n",
      "[82]\tvalidation_0-logloss:0.33407\n",
      "[83]\tvalidation_0-logloss:0.33392\n",
      "[84]\tvalidation_0-logloss:0.33373\n",
      "[85]\tvalidation_0-logloss:0.33374\n",
      "[86]\tvalidation_0-logloss:0.33388\n",
      "[87]\tvalidation_0-logloss:0.33386\n",
      "[88]\tvalidation_0-logloss:0.33382\n",
      "[89]\tvalidation_0-logloss:0.33372\n",
      "[90]\tvalidation_0-logloss:0.33378\n",
      "[91]\tvalidation_0-logloss:0.33382\n",
      "[92]\tvalidation_0-logloss:0.33392\n",
      "[93]\tvalidation_0-logloss:0.33413\n",
      "[94]\tvalidation_0-logloss:0.33380\n",
      "[95]\tvalidation_0-logloss:0.33364\n",
      "[96]\tvalidation_0-logloss:0.33346\n",
      "[97]\tvalidation_0-logloss:0.33327\n",
      "[98]\tvalidation_0-logloss:0.33335\n",
      "[99]\tvalidation_0-logloss:0.33337\n",
      "최적 하이퍼 파라미터:\n",
      " {'colsample_bytree': 0.5, 'learning_rete': 0.01, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 100}\n",
      "최고 예측 정확도: 0.8534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,300],\n",
    "    'max_depth' : [3,5, 7,9], \n",
    "    'min_child_weight' : [1,3,5],\n",
    "    'colsample_bytree' : [0.5,0.75],\n",
    "    'learning_rete':[0.01,0.1]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "clf = XGBClassifier()\n",
    "grid_cv = GridSearchCV(clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train, early_stopping_rounds=30,eval_set=evals, eval_metric=\"logloss\",  verbose=True)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (3.1.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'e:\\모든파일\\프로그래밍\\파이썬\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: scipy in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from lightgbm) (1.5.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from lightgbm) (1.18.5)\n",
      "Requirement already satisfied: wheel in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from lightgbm) (0.36.0)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.530183\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.504188\n",
      "[3]\tvalid_0's binary_logloss: 0.483647\n",
      "[4]\tvalid_0's binary_logloss: 0.46682\n",
      "[5]\tvalid_0's binary_logloss: 0.45286\n",
      "[6]\tvalid_0's binary_logloss: 0.441107\n",
      "[7]\tvalid_0's binary_logloss: 0.430478\n",
      "[8]\tvalid_0's binary_logloss: 0.421791\n",
      "[9]\tvalid_0's binary_logloss: 0.414182\n",
      "[10]\tvalid_0's binary_logloss: 0.407621\n",
      "[11]\tvalid_0's binary_logloss: 0.401764\n",
      "[12]\tvalid_0's binary_logloss: 0.39584\n",
      "[13]\tvalid_0's binary_logloss: 0.391079\n",
      "[14]\tvalid_0's binary_logloss: 0.386677\n",
      "[15]\tvalid_0's binary_logloss: 0.382843\n",
      "[16]\tvalid_0's binary_logloss: 0.379507\n",
      "[17]\tvalid_0's binary_logloss: 0.376336\n",
      "[18]\tvalid_0's binary_logloss: 0.373065\n",
      "[19]\tvalid_0's binary_logloss: 0.370454\n",
      "[20]\tvalid_0's binary_logloss: 0.367871\n",
      "[21]\tvalid_0's binary_logloss: 0.365674\n",
      "[22]\tvalid_0's binary_logloss: 0.363035\n",
      "[23]\tvalid_0's binary_logloss: 0.361394\n",
      "[24]\tvalid_0's binary_logloss: 0.359464\n",
      "[25]\tvalid_0's binary_logloss: 0.358133\n",
      "[26]\tvalid_0's binary_logloss: 0.355799\n",
      "[27]\tvalid_0's binary_logloss: 0.354449\n",
      "[28]\tvalid_0's binary_logloss: 0.352653\n",
      "[29]\tvalid_0's binary_logloss: 0.350656\n",
      "[30]\tvalid_0's binary_logloss: 0.349829\n",
      "[31]\tvalid_0's binary_logloss: 0.348662\n",
      "[32]\tvalid_0's binary_logloss: 0.347997\n",
      "[33]\tvalid_0's binary_logloss: 0.347246\n",
      "[34]\tvalid_0's binary_logloss: 0.346669\n",
      "[35]\tvalid_0's binary_logloss: 0.345438\n",
      "[36]\tvalid_0's binary_logloss: 0.344947\n",
      "[37]\tvalid_0's binary_logloss: 0.343931\n",
      "[38]\tvalid_0's binary_logloss: 0.343171\n",
      "[39]\tvalid_0's binary_logloss: 0.342714\n",
      "[40]\tvalid_0's binary_logloss: 0.341899\n",
      "[41]\tvalid_0's binary_logloss: 0.341547\n",
      "[42]\tvalid_0's binary_logloss: 0.340859\n",
      "[43]\tvalid_0's binary_logloss: 0.340696\n",
      "[44]\tvalid_0's binary_logloss: 0.340133\n",
      "[45]\tvalid_0's binary_logloss: 0.339805\n",
      "[46]\tvalid_0's binary_logloss: 0.339298\n",
      "[47]\tvalid_0's binary_logloss: 0.338966\n",
      "[48]\tvalid_0's binary_logloss: 0.338603\n",
      "[49]\tvalid_0's binary_logloss: 0.338311\n",
      "[50]\tvalid_0's binary_logloss: 0.337951\n",
      "[51]\tvalid_0's binary_logloss: 0.337767\n",
      "[52]\tvalid_0's binary_logloss: 0.33767\n",
      "[53]\tvalid_0's binary_logloss: 0.337194\n",
      "[54]\tvalid_0's binary_logloss: 0.336867\n",
      "[55]\tvalid_0's binary_logloss: 0.336729\n",
      "[56]\tvalid_0's binary_logloss: 0.336525\n",
      "[57]\tvalid_0's binary_logloss: 0.336403\n",
      "[58]\tvalid_0's binary_logloss: 0.336232\n",
      "[59]\tvalid_0's binary_logloss: 0.336032\n",
      "[60]\tvalid_0's binary_logloss: 0.335785\n",
      "[61]\tvalid_0's binary_logloss: 0.335791\n",
      "[62]\tvalid_0's binary_logloss: 0.33555\n",
      "[63]\tvalid_0's binary_logloss: 0.335474\n",
      "[64]\tvalid_0's binary_logloss: 0.335387\n",
      "[65]\tvalid_0's binary_logloss: 0.335111\n",
      "[66]\tvalid_0's binary_logloss: 0.335044\n",
      "[67]\tvalid_0's binary_logloss: 0.334901\n",
      "[68]\tvalid_0's binary_logloss: 0.334951\n",
      "[69]\tvalid_0's binary_logloss: 0.334812\n",
      "[70]\tvalid_0's binary_logloss: 0.334668\n",
      "[71]\tvalid_0's binary_logloss: 0.334554\n",
      "[72]\tvalid_0's binary_logloss: 0.33434\n",
      "[73]\tvalid_0's binary_logloss: 0.334112\n",
      "[74]\tvalid_0's binary_logloss: 0.334099\n",
      "[75]\tvalid_0's binary_logloss: 0.33417\n",
      "[76]\tvalid_0's binary_logloss: 0.33412\n",
      "[77]\tvalid_0's binary_logloss: 0.333991\n",
      "[78]\tvalid_0's binary_logloss: 0.33412\n",
      "[79]\tvalid_0's binary_logloss: 0.334046\n",
      "[80]\tvalid_0's binary_logloss: 0.334097\n",
      "[81]\tvalid_0's binary_logloss: 0.334126\n",
      "[82]\tvalid_0's binary_logloss: 0.334093\n",
      "[83]\tvalid_0's binary_logloss: 0.33399\n",
      "[84]\tvalid_0's binary_logloss: 0.334082\n",
      "[85]\tvalid_0's binary_logloss: 0.333912\n",
      "[86]\tvalid_0's binary_logloss: 0.333924\n",
      "[87]\tvalid_0's binary_logloss: 0.333897\n",
      "[88]\tvalid_0's binary_logloss: 0.333957\n",
      "[89]\tvalid_0's binary_logloss: 0.334015\n",
      "[90]\tvalid_0's binary_logloss: 0.333895\n",
      "[91]\tvalid_0's binary_logloss: 0.33376\n",
      "[92]\tvalid_0's binary_logloss: 0.333713\n",
      "[93]\tvalid_0's binary_logloss: 0.333512\n",
      "[94]\tvalid_0's binary_logloss: 0.333338\n",
      "[95]\tvalid_0's binary_logloss: 0.333393\n",
      "[96]\tvalid_0's binary_logloss: 0.333408\n",
      "[97]\tvalid_0's binary_logloss: 0.333281\n",
      "[98]\tvalid_0's binary_logloss: 0.333401\n",
      "[99]\tvalid_0's binary_logloss: 0.333314\n",
      "[100]\tvalid_0's binary_logloss: 0.333208\n",
      "[101]\tvalid_0's binary_logloss: 0.333305\n",
      "[102]\tvalid_0's binary_logloss: 0.333235\n",
      "[103]\tvalid_0's binary_logloss: 0.333233\n",
      "[104]\tvalid_0's binary_logloss: 0.333114\n",
      "[105]\tvalid_0's binary_logloss: 0.332988\n",
      "[106]\tvalid_0's binary_logloss: 0.332899\n",
      "[107]\tvalid_0's binary_logloss: 0.332975\n",
      "[108]\tvalid_0's binary_logloss: 0.333252\n",
      "[109]\tvalid_0's binary_logloss: 0.333139\n",
      "[110]\tvalid_0's binary_logloss: 0.333111\n",
      "[111]\tvalid_0's binary_logloss: 0.333036\n",
      "[112]\tvalid_0's binary_logloss: 0.333002\n",
      "[113]\tvalid_0's binary_logloss: 0.332993\n",
      "[114]\tvalid_0's binary_logloss: 0.332979\n",
      "[115]\tvalid_0's binary_logloss: 0.333004\n",
      "[116]\tvalid_0's binary_logloss: 0.332941\n",
      "[117]\tvalid_0's binary_logloss: 0.332976\n",
      "[118]\tvalid_0's binary_logloss: 0.332827\n",
      "[119]\tvalid_0's binary_logloss: 0.332812\n",
      "[120]\tvalid_0's binary_logloss: 0.332784\n",
      "[121]\tvalid_0's binary_logloss: 0.332723\n",
      "[122]\tvalid_0's binary_logloss: 0.332669\n",
      "[123]\tvalid_0's binary_logloss: 0.332782\n",
      "[124]\tvalid_0's binary_logloss: 0.332671\n",
      "[125]\tvalid_0's binary_logloss: 0.332783\n",
      "[126]\tvalid_0's binary_logloss: 0.332768\n",
      "[127]\tvalid_0's binary_logloss: 0.332731\n",
      "[128]\tvalid_0's binary_logloss: 0.332694\n",
      "[129]\tvalid_0's binary_logloss: 0.332866\n",
      "[130]\tvalid_0's binary_logloss: 0.332902\n",
      "[131]\tvalid_0's binary_logloss: 0.332841\n",
      "[132]\tvalid_0's binary_logloss: 0.332907\n",
      "[133]\tvalid_0's binary_logloss: 0.332853\n",
      "[134]\tvalid_0's binary_logloss: 0.33281\n",
      "[135]\tvalid_0's binary_logloss: 0.332868\n",
      "[136]\tvalid_0's binary_logloss: 0.332998\n",
      "[137]\tvalid_0's binary_logloss: 0.332953\n",
      "[138]\tvalid_0's binary_logloss: 0.332949\n",
      "[139]\tvalid_0's binary_logloss: 0.33296\n",
      "[140]\tvalid_0's binary_logloss: 0.332894\n",
      "[141]\tvalid_0's binary_logloss: 0.332989\n",
      "[142]\tvalid_0's binary_logloss: 0.333069\n",
      "[143]\tvalid_0's binary_logloss: 0.333136\n",
      "[144]\tvalid_0's binary_logloss: 0.333117\n",
      "[145]\tvalid_0's binary_logloss: 0.333161\n",
      "[146]\tvalid_0's binary_logloss: 0.333099\n",
      "[147]\tvalid_0's binary_logloss: 0.33312\n",
      "[148]\tvalid_0's binary_logloss: 0.333187\n",
      "[149]\tvalid_0's binary_logloss: 0.333363\n",
      "[150]\tvalid_0's binary_logloss: 0.333443\n",
      "[151]\tvalid_0's binary_logloss: 0.333391\n",
      "[152]\tvalid_0's binary_logloss: 0.33347\n",
      "[153]\tvalid_0's binary_logloss: 0.333602\n",
      "[154]\tvalid_0's binary_logloss: 0.333813\n",
      "[155]\tvalid_0's binary_logloss: 0.333929\n",
      "[156]\tvalid_0's binary_logloss: 0.333952\n",
      "[157]\tvalid_0's binary_logloss: 0.333885\n",
      "[158]\tvalid_0's binary_logloss: 0.333762\n",
      "[159]\tvalid_0's binary_logloss: 0.333723\n",
      "[160]\tvalid_0's binary_logloss: 0.333816\n",
      "[161]\tvalid_0's binary_logloss: 0.333774\n",
      "[162]\tvalid_0's binary_logloss: 0.333722\n",
      "[163]\tvalid_0's binary_logloss: 0.333624\n",
      "[164]\tvalid_0's binary_logloss: 0.333681\n",
      "[165]\tvalid_0's binary_logloss: 0.333791\n",
      "[166]\tvalid_0's binary_logloss: 0.333854\n",
      "[167]\tvalid_0's binary_logloss: 0.33383\n",
      "[168]\tvalid_0's binary_logloss: 0.333936\n",
      "[169]\tvalid_0's binary_logloss: 0.334027\n",
      "[170]\tvalid_0's binary_logloss: 0.333985\n",
      "[171]\tvalid_0's binary_logloss: 0.334035\n",
      "[172]\tvalid_0's binary_logloss: 0.333978\n",
      "[173]\tvalid_0's binary_logloss: 0.333926\n",
      "[174]\tvalid_0's binary_logloss: 0.333942\n",
      "[175]\tvalid_0's binary_logloss: 0.333927\n",
      "[176]\tvalid_0's binary_logloss: 0.333941\n",
      "[177]\tvalid_0's binary_logloss: 0.333885\n",
      "[178]\tvalid_0's binary_logloss: 0.333919\n",
      "[179]\tvalid_0's binary_logloss: 0.333929\n",
      "[180]\tvalid_0's binary_logloss: 0.333909\n",
      "[181]\tvalid_0's binary_logloss: 0.333873\n",
      "[182]\tvalid_0's binary_logloss: 0.33384\n",
      "[183]\tvalid_0's binary_logloss: 0.334024\n",
      "[184]\tvalid_0's binary_logloss: 0.334129\n",
      "[185]\tvalid_0's binary_logloss: 0.334167\n",
      "[186]\tvalid_0's binary_logloss: 0.3342\n",
      "[187]\tvalid_0's binary_logloss: 0.334119\n",
      "[188]\tvalid_0's binary_logloss: 0.33421\n",
      "[189]\tvalid_0's binary_logloss: 0.33428\n",
      "[190]\tvalid_0's binary_logloss: 0.334202\n",
      "[191]\tvalid_0's binary_logloss: 0.334209\n",
      "[192]\tvalid_0's binary_logloss: 0.334129\n",
      "[193]\tvalid_0's binary_logloss: 0.334229\n",
      "[194]\tvalid_0's binary_logloss: 0.334302\n",
      "[195]\tvalid_0's binary_logloss: 0.334355\n",
      "[196]\tvalid_0's binary_logloss: 0.334398\n",
      "[197]\tvalid_0's binary_logloss: 0.334478\n",
      "[198]\tvalid_0's binary_logloss: 0.334481\n",
      "[199]\tvalid_0's binary_logloss: 0.334501\n",
      "[200]\tvalid_0's binary_logloss: 0.334547\n",
      "[201]\tvalid_0's binary_logloss: 0.334489\n",
      "[202]\tvalid_0's binary_logloss: 0.334597\n",
      "[203]\tvalid_0's binary_logloss: 0.334595\n",
      "[204]\tvalid_0's binary_logloss: 0.334661\n",
      "[205]\tvalid_0's binary_logloss: 0.334732\n",
      "[206]\tvalid_0's binary_logloss: 0.334834\n",
      "[207]\tvalid_0's binary_logloss: 0.334745\n",
      "[208]\tvalid_0's binary_logloss: 0.334865\n",
      "[209]\tvalid_0's binary_logloss: 0.334874\n",
      "[210]\tvalid_0's binary_logloss: 0.334949\n",
      "[211]\tvalid_0's binary_logloss: 0.335067\n",
      "[212]\tvalid_0's binary_logloss: 0.335179\n",
      "[213]\tvalid_0's binary_logloss: 0.335199\n",
      "[214]\tvalid_0's binary_logloss: 0.335184\n",
      "[215]\tvalid_0's binary_logloss: 0.335265\n",
      "[216]\tvalid_0's binary_logloss: 0.335346\n",
      "[217]\tvalid_0's binary_logloss: 0.335477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[218]\tvalid_0's binary_logloss: 0.335539\n",
      "[219]\tvalid_0's binary_logloss: 0.335466\n",
      "[220]\tvalid_0's binary_logloss: 0.33547\n",
      "[221]\tvalid_0's binary_logloss: 0.335558\n",
      "[222]\tvalid_0's binary_logloss: 0.335619\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's binary_logloss: 0.332669\n"
     ]
    }
   ],
   "source": [
    "#light GBM\n",
    "from lightgbm import LGBMClassifier\n",
    "# 앞서 XGBoost와 동일하게 n_estimators는 400 설정. \n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \n",
    "                 eval_set=evals, verbose=True)\n",
    "preds = lgbm_wrapper.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[5324  315]\n",
      " [ 825 1077]]\n",
      "정확도: 0.8488, 정밀도: 0.7737, 재현율: 0.5662,    F1: 0.6539, AUC:0.7552\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.545516\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.530521\n",
      "[3]\tvalid_0's binary_logloss: 0.517518\n",
      "[4]\tvalid_0's binary_logloss: 0.505974\n",
      "[5]\tvalid_0's binary_logloss: 0.497102\n",
      "[6]\tvalid_0's binary_logloss: 0.491693\n",
      "[7]\tvalid_0's binary_logloss: 0.480476\n",
      "[8]\tvalid_0's binary_logloss: 0.471418\n",
      "[9]\tvalid_0's binary_logloss: 0.461689\n",
      "[10]\tvalid_0's binary_logloss: 0.452\n",
      "[11]\tvalid_0's binary_logloss: 0.446954\n",
      "[12]\tvalid_0's binary_logloss: 0.439527\n",
      "[13]\tvalid_0's binary_logloss: 0.433856\n",
      "[14]\tvalid_0's binary_logloss: 0.429156\n",
      "[15]\tvalid_0's binary_logloss: 0.42567\n",
      "[16]\tvalid_0's binary_logloss: 0.421581\n",
      "[17]\tvalid_0's binary_logloss: 0.416668\n",
      "[18]\tvalid_0's binary_logloss: 0.413651\n",
      "[19]\tvalid_0's binary_logloss: 0.409855\n",
      "[20]\tvalid_0's binary_logloss: 0.40667\n",
      "[21]\tvalid_0's binary_logloss: 0.403797\n",
      "[22]\tvalid_0's binary_logloss: 0.401955\n",
      "[23]\tvalid_0's binary_logloss: 0.399542\n",
      "[24]\tvalid_0's binary_logloss: 0.397314\n",
      "[25]\tvalid_0's binary_logloss: 0.395693\n",
      "[26]\tvalid_0's binary_logloss: 0.393973\n",
      "[27]\tvalid_0's binary_logloss: 0.391606\n",
      "[28]\tvalid_0's binary_logloss: 0.390073\n",
      "[29]\tvalid_0's binary_logloss: 0.387757\n",
      "[30]\tvalid_0's binary_logloss: 0.386165\n",
      "[31]\tvalid_0's binary_logloss: 0.384338\n",
      "[32]\tvalid_0's binary_logloss: 0.382786\n",
      "[33]\tvalid_0's binary_logloss: 0.38168\n",
      "[34]\tvalid_0's binary_logloss: 0.380534\n",
      "[35]\tvalid_0's binary_logloss: 0.379394\n",
      "[36]\tvalid_0's binary_logloss: 0.37848\n",
      "[37]\tvalid_0's binary_logloss: 0.377319\n",
      "[38]\tvalid_0's binary_logloss: 0.376222\n",
      "[39]\tvalid_0's binary_logloss: 0.3756\n",
      "[40]\tvalid_0's binary_logloss: 0.37499\n",
      "[41]\tvalid_0's binary_logloss: 0.374285\n",
      "[42]\tvalid_0's binary_logloss: 0.373438\n",
      "[43]\tvalid_0's binary_logloss: 0.372824\n",
      "[44]\tvalid_0's binary_logloss: 0.371751\n",
      "[45]\tvalid_0's binary_logloss: 0.37118\n",
      "[46]\tvalid_0's binary_logloss: 0.370677\n",
      "[47]\tvalid_0's binary_logloss: 0.370162\n",
      "[48]\tvalid_0's binary_logloss: 0.369544\n",
      "[49]\tvalid_0's binary_logloss: 0.368908\n",
      "[50]\tvalid_0's binary_logloss: 0.368219\n",
      "[51]\tvalid_0's binary_logloss: 0.367573\n",
      "[52]\tvalid_0's binary_logloss: 0.366134\n",
      "[53]\tvalid_0's binary_logloss: 0.365482\n",
      "[54]\tvalid_0's binary_logloss: 0.364914\n",
      "[55]\tvalid_0's binary_logloss: 0.364546\n",
      "[56]\tvalid_0's binary_logloss: 0.363444\n",
      "[57]\tvalid_0's binary_logloss: 0.362894\n",
      "[58]\tvalid_0's binary_logloss: 0.36234\n",
      "[59]\tvalid_0's binary_logloss: 0.362176\n",
      "[60]\tvalid_0's binary_logloss: 0.361961\n",
      "[61]\tvalid_0's binary_logloss: 0.360864\n",
      "[62]\tvalid_0's binary_logloss: 0.360665\n",
      "[63]\tvalid_0's binary_logloss: 0.359793\n",
      "[64]\tvalid_0's binary_logloss: 0.359451\n",
      "[65]\tvalid_0's binary_logloss: 0.359143\n",
      "[66]\tvalid_0's binary_logloss: 0.359012\n",
      "[67]\tvalid_0's binary_logloss: 0.358834\n",
      "[68]\tvalid_0's binary_logloss: 0.35878\n",
      "[69]\tvalid_0's binary_logloss: 0.35854\n",
      "[70]\tvalid_0's binary_logloss: 0.358251\n",
      "[71]\tvalid_0's binary_logloss: 0.35796\n",
      "[72]\tvalid_0's binary_logloss: 0.357537\n",
      "[73]\tvalid_0's binary_logloss: 0.357343\n",
      "[74]\tvalid_0's binary_logloss: 0.357143\n",
      "[75]\tvalid_0's binary_logloss: 0.356851\n",
      "[76]\tvalid_0's binary_logloss: 0.3565\n",
      "[77]\tvalid_0's binary_logloss: 0.356151\n",
      "[78]\tvalid_0's binary_logloss: 0.355566\n",
      "[79]\tvalid_0's binary_logloss: 0.355385\n",
      "[80]\tvalid_0's binary_logloss: 0.355167\n",
      "[81]\tvalid_0's binary_logloss: 0.354318\n",
      "[82]\tvalid_0's binary_logloss: 0.354293\n",
      "[83]\tvalid_0's binary_logloss: 0.354217\n",
      "[84]\tvalid_0's binary_logloss: 0.35414\n",
      "[85]\tvalid_0's binary_logloss: 0.354056\n",
      "[86]\tvalid_0's binary_logloss: 0.35395\n",
      "[87]\tvalid_0's binary_logloss: 0.353659\n",
      "[88]\tvalid_0's binary_logloss: 0.353228\n",
      "[89]\tvalid_0's binary_logloss: 0.353042\n",
      "[90]\tvalid_0's binary_logloss: 0.352973\n",
      "[91]\tvalid_0's binary_logloss: 0.352805\n",
      "[92]\tvalid_0's binary_logloss: 0.35268\n",
      "[93]\tvalid_0's binary_logloss: 0.35262\n",
      "[94]\tvalid_0's binary_logloss: 0.352557\n",
      "[95]\tvalid_0's binary_logloss: 0.352217\n",
      "[96]\tvalid_0's binary_logloss: 0.352168\n",
      "[97]\tvalid_0's binary_logloss: 0.351992\n",
      "[98]\tvalid_0's binary_logloss: 0.351985\n",
      "[99]\tvalid_0's binary_logloss: 0.351905\n",
      "[100]\tvalid_0's binary_logloss: 0.351746\n",
      "[101]\tvalid_0's binary_logloss: 0.351572\n",
      "[102]\tvalid_0's binary_logloss: 0.351483\n",
      "[103]\tvalid_0's binary_logloss: 0.351357\n",
      "[104]\tvalid_0's binary_logloss: 0.351221\n",
      "[105]\tvalid_0's binary_logloss: 0.35115\n",
      "[106]\tvalid_0's binary_logloss: 0.350612\n",
      "[107]\tvalid_0's binary_logloss: 0.350378\n",
      "[108]\tvalid_0's binary_logloss: 0.350179\n",
      "[109]\tvalid_0's binary_logloss: 0.34965\n",
      "[110]\tvalid_0's binary_logloss: 0.349572\n",
      "[111]\tvalid_0's binary_logloss: 0.349556\n",
      "[112]\tvalid_0's binary_logloss: 0.349342\n",
      "[113]\tvalid_0's binary_logloss: 0.348862\n",
      "[114]\tvalid_0's binary_logloss: 0.348298\n",
      "[115]\tvalid_0's binary_logloss: 0.348277\n",
      "[116]\tvalid_0's binary_logloss: 0.347944\n",
      "[117]\tvalid_0's binary_logloss: 0.347907\n",
      "[118]\tvalid_0's binary_logloss: 0.347727\n",
      "[119]\tvalid_0's binary_logloss: 0.34739\n",
      "[120]\tvalid_0's binary_logloss: 0.346962\n",
      "[121]\tvalid_0's binary_logloss: 0.34678\n",
      "[122]\tvalid_0's binary_logloss: 0.346775\n",
      "[123]\tvalid_0's binary_logloss: 0.34678\n",
      "[124]\tvalid_0's binary_logloss: 0.346417\n",
      "[125]\tvalid_0's binary_logloss: 0.346288\n",
      "[126]\tvalid_0's binary_logloss: 0.346129\n",
      "[127]\tvalid_0's binary_logloss: 0.345911\n",
      "[128]\tvalid_0's binary_logloss: 0.34584\n",
      "[129]\tvalid_0's binary_logloss: 0.345824\n",
      "[130]\tvalid_0's binary_logloss: 0.345524\n",
      "[131]\tvalid_0's binary_logloss: 0.345567\n",
      "[132]\tvalid_0's binary_logloss: 0.345415\n",
      "[133]\tvalid_0's binary_logloss: 0.344978\n",
      "[134]\tvalid_0's binary_logloss: 0.344851\n",
      "[135]\tvalid_0's binary_logloss: 0.34484\n",
      "[136]\tvalid_0's binary_logloss: 0.344938\n",
      "[137]\tvalid_0's binary_logloss: 0.34491\n",
      "[138]\tvalid_0's binary_logloss: 0.344928\n",
      "[139]\tvalid_0's binary_logloss: 0.344663\n",
      "[140]\tvalid_0's binary_logloss: 0.344675\n",
      "[141]\tvalid_0's binary_logloss: 0.344537\n",
      "[142]\tvalid_0's binary_logloss: 0.344178\n",
      "[143]\tvalid_0's binary_logloss: 0.343964\n",
      "[144]\tvalid_0's binary_logloss: 0.343937\n",
      "[145]\tvalid_0's binary_logloss: 0.343984\n",
      "[146]\tvalid_0's binary_logloss: 0.343933\n",
      "[147]\tvalid_0's binary_logloss: 0.343708\n",
      "[148]\tvalid_0's binary_logloss: 0.343387\n",
      "[149]\tvalid_0's binary_logloss: 0.343214\n",
      "[150]\tvalid_0's binary_logloss: 0.343137\n",
      "[151]\tvalid_0's binary_logloss: 0.34324\n",
      "[152]\tvalid_0's binary_logloss: 0.343199\n",
      "[153]\tvalid_0's binary_logloss: 0.343063\n",
      "[154]\tvalid_0's binary_logloss: 0.343025\n",
      "[155]\tvalid_0's binary_logloss: 0.34287\n",
      "[156]\tvalid_0's binary_logloss: 0.342848\n",
      "[157]\tvalid_0's binary_logloss: 0.342697\n",
      "[158]\tvalid_0's binary_logloss: 0.342544\n",
      "[159]\tvalid_0's binary_logloss: 0.342501\n",
      "[160]\tvalid_0's binary_logloss: 0.342252\n",
      "[161]\tvalid_0's binary_logloss: 0.34196\n",
      "[162]\tvalid_0's binary_logloss: 0.341878\n",
      "[163]\tvalid_0's binary_logloss: 0.341811\n",
      "[164]\tvalid_0's binary_logloss: 0.341906\n",
      "[165]\tvalid_0's binary_logloss: 0.341727\n",
      "[166]\tvalid_0's binary_logloss: 0.341545\n",
      "[167]\tvalid_0's binary_logloss: 0.341556\n",
      "[168]\tvalid_0's binary_logloss: 0.341506\n",
      "[169]\tvalid_0's binary_logloss: 0.341392\n",
      "[170]\tvalid_0's binary_logloss: 0.341272\n",
      "[171]\tvalid_0's binary_logloss: 0.341293\n",
      "[172]\tvalid_0's binary_logloss: 0.341184\n",
      "[173]\tvalid_0's binary_logloss: 0.341204\n",
      "[174]\tvalid_0's binary_logloss: 0.341038\n",
      "[175]\tvalid_0's binary_logloss: 0.341063\n",
      "[176]\tvalid_0's binary_logloss: 0.341033\n",
      "[177]\tvalid_0's binary_logloss: 0.340846\n",
      "[178]\tvalid_0's binary_logloss: 0.340765\n",
      "[179]\tvalid_0's binary_logloss: 0.340663\n",
      "[180]\tvalid_0's binary_logloss: 0.340649\n",
      "[181]\tvalid_0's binary_logloss: 0.340553\n",
      "[182]\tvalid_0's binary_logloss: 0.340312\n",
      "[183]\tvalid_0's binary_logloss: 0.340262\n",
      "[184]\tvalid_0's binary_logloss: 0.340214\n",
      "[185]\tvalid_0's binary_logloss: 0.340127\n",
      "[186]\tvalid_0's binary_logloss: 0.340015\n",
      "[187]\tvalid_0's binary_logloss: 0.340001\n",
      "[188]\tvalid_0's binary_logloss: 0.339964\n",
      "[189]\tvalid_0's binary_logloss: 0.339833\n",
      "[190]\tvalid_0's binary_logloss: 0.339835\n",
      "[191]\tvalid_0's binary_logloss: 0.339852\n",
      "[192]\tvalid_0's binary_logloss: 0.339844\n",
      "[193]\tvalid_0's binary_logloss: 0.339692\n",
      "[194]\tvalid_0's binary_logloss: 0.339556\n",
      "[195]\tvalid_0's binary_logloss: 0.33952\n",
      "[196]\tvalid_0's binary_logloss: 0.339542\n",
      "[197]\tvalid_0's binary_logloss: 0.339452\n",
      "[198]\tvalid_0's binary_logloss: 0.33945\n",
      "[199]\tvalid_0's binary_logloss: 0.33948\n",
      "[200]\tvalid_0's binary_logloss: 0.339477\n",
      "[201]\tvalid_0's binary_logloss: 0.339351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[202]\tvalid_0's binary_logloss: 0.339293\n",
      "[203]\tvalid_0's binary_logloss: 0.339241\n",
      "[204]\tvalid_0's binary_logloss: 0.339267\n",
      "[205]\tvalid_0's binary_logloss: 0.339167\n",
      "[206]\tvalid_0's binary_logloss: 0.339154\n",
      "[207]\tvalid_0's binary_logloss: 0.339053\n",
      "[208]\tvalid_0's binary_logloss: 0.339093\n",
      "[209]\tvalid_0's binary_logloss: 0.339076\n",
      "[210]\tvalid_0's binary_logloss: 0.339037\n",
      "[211]\tvalid_0's binary_logloss: 0.338974\n",
      "[212]\tvalid_0's binary_logloss: 0.338926\n",
      "[213]\tvalid_0's binary_logloss: 0.338833\n",
      "[214]\tvalid_0's binary_logloss: 0.338813\n",
      "[215]\tvalid_0's binary_logloss: 0.338776\n",
      "[216]\tvalid_0's binary_logloss: 0.33865\n",
      "[217]\tvalid_0's binary_logloss: 0.338626\n",
      "[218]\tvalid_0's binary_logloss: 0.338546\n",
      "[219]\tvalid_0's binary_logloss: 0.338297\n",
      "[220]\tvalid_0's binary_logloss: 0.338318\n",
      "[221]\tvalid_0's binary_logloss: 0.33829\n",
      "[222]\tvalid_0's binary_logloss: 0.338311\n",
      "[223]\tvalid_0's binary_logloss: 0.338264\n",
      "[224]\tvalid_0's binary_logloss: 0.338157\n",
      "[225]\tvalid_0's binary_logloss: 0.338132\n",
      "[226]\tvalid_0's binary_logloss: 0.338047\n",
      "[227]\tvalid_0's binary_logloss: 0.338025\n",
      "[228]\tvalid_0's binary_logloss: 0.337994\n",
      "[229]\tvalid_0's binary_logloss: 0.337835\n",
      "[230]\tvalid_0's binary_logloss: 0.337762\n",
      "[231]\tvalid_0's binary_logloss: 0.337688\n",
      "[232]\tvalid_0's binary_logloss: 0.337487\n",
      "[233]\tvalid_0's binary_logloss: 0.337405\n",
      "[234]\tvalid_0's binary_logloss: 0.337383\n",
      "[235]\tvalid_0's binary_logloss: 0.33738\n",
      "[236]\tvalid_0's binary_logloss: 0.337348\n",
      "[237]\tvalid_0's binary_logloss: 0.337339\n",
      "[238]\tvalid_0's binary_logloss: 0.337329\n",
      "[239]\tvalid_0's binary_logloss: 0.337248\n",
      "[240]\tvalid_0's binary_logloss: 0.337237\n",
      "[241]\tvalid_0's binary_logloss: 0.337245\n",
      "[242]\tvalid_0's binary_logloss: 0.337236\n",
      "[243]\tvalid_0's binary_logloss: 0.337251\n",
      "[244]\tvalid_0's binary_logloss: 0.33718\n",
      "[245]\tvalid_0's binary_logloss: 0.33712\n",
      "[246]\tvalid_0's binary_logloss: 0.337105\n",
      "[247]\tvalid_0's binary_logloss: 0.337088\n",
      "[248]\tvalid_0's binary_logloss: 0.336999\n",
      "[249]\tvalid_0's binary_logloss: 0.33696\n",
      "[250]\tvalid_0's binary_logloss: 0.336949\n",
      "[251]\tvalid_0's binary_logloss: 0.336811\n",
      "[252]\tvalid_0's binary_logloss: 0.336733\n",
      "[253]\tvalid_0's binary_logloss: 0.336692\n",
      "[254]\tvalid_0's binary_logloss: 0.336693\n",
      "[255]\tvalid_0's binary_logloss: 0.336669\n",
      "[256]\tvalid_0's binary_logloss: 0.336716\n",
      "[257]\tvalid_0's binary_logloss: 0.336643\n",
      "[258]\tvalid_0's binary_logloss: 0.336617\n",
      "[259]\tvalid_0's binary_logloss: 0.336618\n",
      "[260]\tvalid_0's binary_logloss: 0.336591\n",
      "[261]\tvalid_0's binary_logloss: 0.336572\n",
      "[262]\tvalid_0's binary_logloss: 0.336598\n",
      "[263]\tvalid_0's binary_logloss: 0.336488\n",
      "[264]\tvalid_0's binary_logloss: 0.336399\n",
      "[265]\tvalid_0's binary_logloss: 0.336423\n",
      "[266]\tvalid_0's binary_logloss: 0.336303\n",
      "[267]\tvalid_0's binary_logloss: 0.336317\n",
      "[268]\tvalid_0's binary_logloss: 0.336265\n",
      "[269]\tvalid_0's binary_logloss: 0.336187\n",
      "[270]\tvalid_0's binary_logloss: 0.336134\n",
      "[271]\tvalid_0's binary_logloss: 0.336082\n",
      "[272]\tvalid_0's binary_logloss: 0.336022\n",
      "[273]\tvalid_0's binary_logloss: 0.335965\n",
      "[274]\tvalid_0's binary_logloss: 0.335937\n",
      "[275]\tvalid_0's binary_logloss: 0.335975\n",
      "[276]\tvalid_0's binary_logloss: 0.335947\n",
      "[277]\tvalid_0's binary_logloss: 0.335916\n",
      "[278]\tvalid_0's binary_logloss: 0.335928\n",
      "[279]\tvalid_0's binary_logloss: 0.335847\n",
      "[280]\tvalid_0's binary_logloss: 0.335826\n",
      "[281]\tvalid_0's binary_logloss: 0.335704\n",
      "[282]\tvalid_0's binary_logloss: 0.335698\n",
      "[283]\tvalid_0's binary_logloss: 0.3357\n",
      "[284]\tvalid_0's binary_logloss: 0.335655\n",
      "[285]\tvalid_0's binary_logloss: 0.335601\n",
      "[286]\tvalid_0's binary_logloss: 0.335539\n",
      "[287]\tvalid_0's binary_logloss: 0.335514\n",
      "[288]\tvalid_0's binary_logloss: 0.335455\n",
      "[289]\tvalid_0's binary_logloss: 0.335414\n",
      "[290]\tvalid_0's binary_logloss: 0.335483\n",
      "[291]\tvalid_0's binary_logloss: 0.335439\n",
      "[292]\tvalid_0's binary_logloss: 0.335419\n",
      "[293]\tvalid_0's binary_logloss: 0.335441\n",
      "[294]\tvalid_0's binary_logloss: 0.335481\n",
      "[295]\tvalid_0's binary_logloss: 0.335395\n",
      "[296]\tvalid_0's binary_logloss: 0.335301\n",
      "[297]\tvalid_0's binary_logloss: 0.335275\n",
      "[298]\tvalid_0's binary_logloss: 0.335203\n",
      "[299]\tvalid_0's binary_logloss: 0.335217\n",
      "[300]\tvalid_0's binary_logloss: 0.33512\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's binary_logloss: 0.33512\n",
      "최적 하이퍼 파라미터:\n",
      " {'colsample_bytree': 0.5, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 300}\n",
      "최고 예측 정확도: 0.8534\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[100,300],\n",
    "    'max_depth' : [3,5, 7,9], \n",
    "    'min_child_weight' : [1,3,5],\n",
    "    'colsample_bytree' : [0.5,0.75]\n",
    "}\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "clf = LGBMClassifier()\n",
    "grid_cv = GridSearchCV(clf , param_grid=params , cv=2, n_jobs=-1 )\n",
    "grid_cv.fit(X_train , y_train, early_stopping_rounds=30,eval_set=evals, eval_metric=\"logloss\",  verbose=True)\n",
    "\n",
    "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (2.3.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'e:\\모든파일\\프로그래밍\\파이썬\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: grpcio>=1.8.6 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: astunparse==1.6.3 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.25.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (50.3.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.26.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: scipy>=0.14 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from keras) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: h5py in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in e:\\모든파일\\프로그래밍\\파이썬\\venv\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'e:\\모든파일\\프로그래밍\\파이썬\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝코드\n",
    "\n",
    "# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옵니다.\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 필요한 라이브러리를 불러옵니다.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.4846 - accuracy: 0.7706\n",
      "Epoch 2/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8226\n",
      "Epoch 3/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3837 - accuracy: 0.8275\n",
      "Epoch 4/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3792 - accuracy: 0.8273\n",
      "Epoch 5/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8286\n",
      "Epoch 6/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3751 - accuracy: 0.8288\n",
      "Epoch 7/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8302\n",
      "Epoch 8/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8300\n",
      "Epoch 9/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8300\n",
      "Epoch 10/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8293\n",
      "Epoch 11/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8308\n",
      "Epoch 12/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8306\n",
      "Epoch 13/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3697 - accuracy: 0.8316\n",
      "Epoch 14/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8314\n",
      "Epoch 15/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3687 - accuracy: 0.8313\n",
      "Epoch 16/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3683 - accuracy: 0.8314\n",
      "Epoch 17/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3682 - accuracy: 0.8317\n",
      "Epoch 18/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8317\n",
      "Epoch 19/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3667 - accuracy: 0.8315\n",
      "Epoch 20/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3665 - accuracy: 0.8327\n",
      "Epoch 21/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3663 - accuracy: 0.8323\n",
      "Epoch 22/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3656 - accuracy: 0.8335\n",
      "Epoch 23/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3654 - accuracy: 0.8329\n",
      "Epoch 24/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3653 - accuracy: 0.8322\n",
      "Epoch 25/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3643 - accuracy: 0.8336\n",
      "Epoch 26/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8337\n",
      "Epoch 27/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3633 - accuracy: 0.8348\n",
      "Epoch 28/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3632 - accuracy: 0.8327\n",
      "Epoch 29/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3626 - accuracy: 0.8345\n",
      "Epoch 30/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3627 - accuracy: 0.8350\n",
      "Epoch 31/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3618 - accuracy: 0.8346\n",
      "Epoch 32/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8345\n",
      "Epoch 33/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3615 - accuracy: 0.8361\n",
      "Epoch 34/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8348\n",
      "Epoch 35/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3608 - accuracy: 0.8344\n",
      "Epoch 36/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3610 - accuracy: 0.8352\n",
      "Epoch 37/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3602 - accuracy: 0.8362\n",
      "Epoch 38/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3603 - accuracy: 0.8361\n",
      "Epoch 39/1000\n",
      "227/227 [==============================] - 0s 976us/step - loss: 0.3598 - accuracy: 0.8343\n",
      "Epoch 40/1000\n",
      "227/227 [==============================] - 0s 955us/step - loss: 0.3591 - accuracy: 0.8356\n",
      "Epoch 41/1000\n",
      "227/227 [==============================] - 0s 969us/step - loss: 0.3590 - accuracy: 0.8361\n",
      "Epoch 42/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8352\n",
      "Epoch 43/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3587 - accuracy: 0.8361\n",
      "Epoch 44/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3580 - accuracy: 0.8362\n",
      "Epoch 45/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.8371\n",
      "Epoch 46/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3572 - accuracy: 0.8367\n",
      "Epoch 47/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3567 - accuracy: 0.8384: 0s - loss: 0.3619 - accuracy\n",
      "Epoch 48/1000\n",
      "227/227 [==============================] - 0s 951us/step - loss: 0.3567 - accuracy: 0.8372\n",
      "Epoch 49/1000\n",
      "227/227 [==============================] - 0s 870us/step - loss: 0.3564 - accuracy: 0.8377\n",
      "Epoch 50/1000\n",
      "227/227 [==============================] - 0s 881us/step - loss: 0.3564 - accuracy: 0.8375\n",
      "Epoch 51/1000\n",
      "227/227 [==============================] - 0s 894us/step - loss: 0.3554 - accuracy: 0.8386\n",
      "Epoch 52/1000\n",
      "227/227 [==============================] - 0s 872us/step - loss: 0.3561 - accuracy: 0.8380\n",
      "Epoch 53/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3551 - accuracy: 0.8388\n",
      "Epoch 54/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3547 - accuracy: 0.8390\n",
      "Epoch 55/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8382\n",
      "Epoch 56/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3549 - accuracy: 0.8385\n",
      "Epoch 57/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8390\n",
      "Epoch 58/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8383\n",
      "Epoch 59/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8397\n",
      "Epoch 60/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3532 - accuracy: 0.8387\n",
      "Epoch 61/1000\n",
      "227/227 [==============================] - 0s 888us/step - loss: 0.3534 - accuracy: 0.8382\n",
      "Epoch 62/1000\n",
      "227/227 [==============================] - 0s 867us/step - loss: 0.3538 - accuracy: 0.8374\n",
      "Epoch 63/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3528 - accuracy: 0.8397\n",
      "Epoch 64/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3530 - accuracy: 0.8379\n",
      "Epoch 65/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8387\n",
      "Epoch 66/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.8393\n",
      "Epoch 67/1000\n",
      "227/227 [==============================] - 0s 889us/step - loss: 0.3524 - accuracy: 0.8398\n",
      "Epoch 68/1000\n",
      "227/227 [==============================] - 0s 931us/step - loss: 0.3518 - accuracy: 0.8402\n",
      "Epoch 69/1000\n",
      "227/227 [==============================] - 0s 885us/step - loss: 0.3523 - accuracy: 0.8396\n",
      "Epoch 70/1000\n",
      "227/227 [==============================] - 0s 823us/step - loss: 0.3523 - accuracy: 0.8383\n",
      "Epoch 71/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3513 - accuracy: 0.8397\n",
      "Epoch 72/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3513 - accuracy: 0.8401\n",
      "Epoch 73/1000\n",
      "227/227 [==============================] - 0s 817us/step - loss: 0.3515 - accuracy: 0.8393\n",
      "Epoch 74/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8409\n",
      "Epoch 75/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8405\n",
      "Epoch 76/1000\n",
      "227/227 [==============================] - 0s 826us/step - loss: 0.3508 - accuracy: 0.8409\n",
      "Epoch 77/1000\n",
      "227/227 [==============================] - 0s 845us/step - loss: 0.3506 - accuracy: 0.8409\n",
      "Epoch 78/1000\n",
      "227/227 [==============================] - 0s 892us/step - loss: 0.3504 - accuracy: 0.8403\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 810us/step - loss: 0.3500 - accuracy: 0.8406\n",
      "Epoch 80/1000\n",
      "227/227 [==============================] - 0s 784us/step - loss: 0.3501 - accuracy: 0.8404\n",
      "Epoch 81/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8391\n",
      "Epoch 82/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3499 - accuracy: 0.8403\n",
      "Epoch 83/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3500 - accuracy: 0.8405: 0s - loss: 0\n",
      "Epoch 84/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.8400: 0s - loss:\n",
      "Epoch 85/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8405\n",
      "Epoch 86/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8406\n",
      "Epoch 87/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3496 - accuracy: 0.8395\n",
      "Epoch 88/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8409\n",
      "Epoch 89/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8406\n",
      "Epoch 90/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3494 - accuracy: 0.8399\n",
      "Epoch 91/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3489 - accuracy: 0.8406\n",
      "Epoch 92/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8412\n",
      "Epoch 93/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3488 - accuracy: 0.8409\n",
      "Epoch 94/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8409\n",
      "Epoch 95/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8422\n",
      "Epoch 96/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8404\n",
      "Epoch 97/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8406\n",
      "Epoch 98/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8411\n",
      "Epoch 99/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3485 - accuracy: 0.8412\n",
      "Epoch 100/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3487 - accuracy: 0.8415\n",
      "Epoch 101/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8399\n",
      "Epoch 102/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8401\n",
      "Epoch 103/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8412\n",
      "Epoch 104/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8420\n",
      "Epoch 105/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3479 - accuracy: 0.8422\n",
      "Epoch 106/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3481 - accuracy: 0.8413\n",
      "Epoch 107/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8407\n",
      "Epoch 108/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3478 - accuracy: 0.8421\n",
      "Epoch 109/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3476 - accuracy: 0.8413\n",
      "Epoch 110/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3476 - accuracy: 0.8409\n",
      "Epoch 111/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3473 - accuracy: 0.8407\n",
      "Epoch 112/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8417\n",
      "Epoch 113/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8416\n",
      "Epoch 114/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3475 - accuracy: 0.8403\n",
      "Epoch 115/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3470 - accuracy: 0.8401\n",
      "Epoch 116/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8419\n",
      "Epoch 117/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8406\n",
      "Epoch 118/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3471 - accuracy: 0.8405\n",
      "Epoch 119/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8425\n",
      "Epoch 120/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8399\n",
      "Epoch 121/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8414\n",
      "Epoch 122/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3468 - accuracy: 0.8412\n",
      "Epoch 123/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8415\n",
      "Epoch 124/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8422\n",
      "Epoch 125/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3459 - accuracy: 0.8422\n",
      "Epoch 126/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8408\n",
      "Epoch 127/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8425\n",
      "Epoch 128/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3463 - accuracy: 0.8425\n",
      "Epoch 129/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3463 - accuracy: 0.8419\n",
      "Epoch 130/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8427\n",
      "Epoch 131/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8422\n",
      "Epoch 132/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8420\n",
      "Epoch 133/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3460 - accuracy: 0.8421\n",
      "Epoch 134/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3461 - accuracy: 0.8430\n",
      "Epoch 135/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3455 - accuracy: 0.8434\n",
      "Epoch 136/1000\n",
      "227/227 [==============================] - 0s 929us/step - loss: 0.3457 - accuracy: 0.8418\n",
      "Epoch 137/1000\n",
      "227/227 [==============================] - 0s 906us/step - loss: 0.3454 - accuracy: 0.8424\n",
      "Epoch 138/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3456 - accuracy: 0.8425\n",
      "Epoch 139/1000\n",
      "227/227 [==============================] - 0s 903us/step - loss: 0.3449 - accuracy: 0.8433\n",
      "Epoch 140/1000\n",
      "227/227 [==============================] - 0s 903us/step - loss: 0.3451 - accuracy: 0.8425\n",
      "Epoch 141/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8431\n",
      "Epoch 142/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8424\n",
      "Epoch 143/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3452 - accuracy: 0.8424\n",
      "Epoch 144/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8428\n",
      "Epoch 145/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3448 - accuracy: 0.8441\n",
      "Epoch 146/1000\n",
      "227/227 [==============================] - 0s 888us/step - loss: 0.3447 - accuracy: 0.8417\n",
      "Epoch 147/1000\n",
      "227/227 [==============================] - 0s 823us/step - loss: 0.3449 - accuracy: 0.8428\n",
      "Epoch 148/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3446 - accuracy: 0.8438\n",
      "Epoch 149/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.8441\n",
      "Epoch 150/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3447 - accuracy: 0.8420\n",
      "Epoch 151/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3446 - accuracy: 0.8426\n",
      "Epoch 152/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8422\n",
      "Epoch 153/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8424\n",
      "Epoch 154/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8426\n",
      "Epoch 155/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3446 - accuracy: 0.8433\n",
      "Epoch 156/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3438 - accuracy: 0.8430\n",
      "Epoch 157/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8429\n",
      "Epoch 158/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3439 - accuracy: 0.8441\n",
      "Epoch 159/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8439\n",
      "Epoch 160/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8428\n",
      "Epoch 161/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8434\n",
      "Epoch 162/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8429\n",
      "Epoch 163/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8432\n",
      "Epoch 164/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.8435\n",
      "Epoch 165/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3435 - accuracy: 0.8434\n",
      "Epoch 166/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8422\n",
      "Epoch 167/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3436 - accuracy: 0.8434\n",
      "Epoch 168/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3431 - accuracy: 0.8433\n",
      "Epoch 169/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8431\n",
      "Epoch 170/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8441\n",
      "Epoch 171/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3427 - accuracy: 0.8429\n",
      "Epoch 172/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3428 - accuracy: 0.8438\n",
      "Epoch 173/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3429 - accuracy: 0.8440\n",
      "Epoch 174/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8433\n",
      "Epoch 175/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8446\n",
      "Epoch 176/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8438\n",
      "Epoch 177/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8448\n",
      "Epoch 178/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8435\n",
      "Epoch 179/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3424 - accuracy: 0.8443\n",
      "Epoch 180/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3425 - accuracy: 0.8439\n",
      "Epoch 181/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3422 - accuracy: 0.8443\n",
      "Epoch 182/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8428\n",
      "Epoch 183/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.3421 - accuracy: 0.8442\n",
      "Epoch 184/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8438\n",
      "Epoch 185/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3425 - accuracy: 0.8436\n",
      "Epoch 186/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8439\n",
      "Epoch 187/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8441\n",
      "Epoch 188/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3413 - accuracy: 0.8443\n",
      "Epoch 189/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8431\n",
      "Epoch 190/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8448\n",
      "Epoch 191/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8439\n",
      "Epoch 192/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8441\n",
      "Epoch 193/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3423 - accuracy: 0.8432\n",
      "Epoch 194/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3420 - accuracy: 0.8433\n",
      "Epoch 195/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8442\n",
      "Epoch 196/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3412 - accuracy: 0.8442\n",
      "Epoch 197/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8442\n",
      "Epoch 198/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3416 - accuracy: 0.8442\n",
      "Epoch 199/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3414 - accuracy: 0.8427\n",
      "Epoch 200/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8436\n",
      "Epoch 201/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8428\n",
      "Epoch 202/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8440\n",
      "Epoch 203/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3413 - accuracy: 0.8446\n",
      "Epoch 204/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8440\n",
      "Epoch 205/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8442\n",
      "Epoch 206/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3409 - accuracy: 0.8438\n",
      "Epoch 207/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.8452\n",
      "Epoch 208/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8436\n",
      "Epoch 209/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8451\n",
      "Epoch 210/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8447\n",
      "Epoch 211/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8429\n",
      "Epoch 212/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8437\n",
      "Epoch 213/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8452\n",
      "Epoch 214/1000\n",
      "227/227 [==============================] - 0s 773us/step - loss: 0.3404 - accuracy: 0.8440\n",
      "Epoch 215/1000\n",
      "227/227 [==============================] - 0s 753us/step - loss: 0.3402 - accuracy: 0.8443\n",
      "Epoch 216/1000\n",
      "227/227 [==============================] - 0s 751us/step - loss: 0.3400 - accuracy: 0.8448\n",
      "Epoch 217/1000\n",
      "227/227 [==============================] - 0s 762us/step - loss: 0.3401 - accuracy: 0.8450\n",
      "Epoch 218/1000\n",
      "227/227 [==============================] - 0s 748us/step - loss: 0.3398 - accuracy: 0.8446\n",
      "Epoch 219/1000\n",
      "227/227 [==============================] - 0s 819us/step - loss: 0.3392 - accuracy: 0.8455\n",
      "Epoch 220/1000\n",
      "227/227 [==============================] - 0s 832us/step - loss: 0.3395 - accuracy: 0.8439\n",
      "Epoch 221/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3401 - accuracy: 0.8433\n",
      "Epoch 222/1000\n",
      "227/227 [==============================] - 0s 854us/step - loss: 0.3406 - accuracy: 0.8449\n",
      "Epoch 223/1000\n",
      "227/227 [==============================] - 0s 810us/step - loss: 0.3400 - accuracy: 0.8430\n",
      "Epoch 224/1000\n",
      "227/227 [==============================] - 0s 867us/step - loss: 0.3395 - accuracy: 0.8438\n",
      "Epoch 225/1000\n",
      "227/227 [==============================] - 0s 863us/step - loss: 0.3398 - accuracy: 0.8458\n",
      "Epoch 226/1000\n",
      "227/227 [==============================] - 0s 757us/step - loss: 0.3399 - accuracy: 0.8444\n",
      "Epoch 227/1000\n",
      "227/227 [==============================] - 0s 752us/step - loss: 0.3398 - accuracy: 0.8455\n",
      "Epoch 228/1000\n",
      "227/227 [==============================] - 0s 753us/step - loss: 0.3395 - accuracy: 0.8449\n",
      "Epoch 229/1000\n",
      "227/227 [==============================] - 0s 882us/step - loss: 0.3395 - accuracy: 0.8457\n",
      "Epoch 230/1000\n",
      "227/227 [==============================] - 0s 823us/step - loss: 0.3396 - accuracy: 0.8447\n",
      "Epoch 231/1000\n",
      "227/227 [==============================] - 0s 832us/step - loss: 0.3396 - accuracy: 0.8436\n",
      "Epoch 232/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3393 - accuracy: 0.8442\n",
      "Epoch 233/1000\n",
      "227/227 [==============================] - 0s 859us/step - loss: 0.3395 - accuracy: 0.8452\n",
      "Epoch 234/1000\n",
      "227/227 [==============================] - 0s 845us/step - loss: 0.3385 - accuracy: 0.8453\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 837us/step - loss: 0.3392 - accuracy: 0.8444\n",
      "Epoch 236/1000\n",
      "227/227 [==============================] - 0s 819us/step - loss: 0.3390 - accuracy: 0.8457\n",
      "Epoch 237/1000\n",
      "227/227 [==============================] - 0s 775us/step - loss: 0.3393 - accuracy: 0.8436\n",
      "Epoch 238/1000\n",
      "227/227 [==============================] - 0s 753us/step - loss: 0.3393 - accuracy: 0.8441\n",
      "Epoch 239/1000\n",
      "227/227 [==============================] - 0s 748us/step - loss: 0.3391 - accuracy: 0.8443\n",
      "Epoch 240/1000\n",
      "227/227 [==============================] - 0s 767us/step - loss: 0.3391 - accuracy: 0.8442\n",
      "Epoch 241/1000\n",
      "227/227 [==============================] - 0s 756us/step - loss: 0.3399 - accuracy: 0.8448\n",
      "Epoch 242/1000\n",
      "227/227 [==============================] - 0s 753us/step - loss: 0.3389 - accuracy: 0.8456\n",
      "Epoch 243/1000\n",
      "227/227 [==============================] - 0s 823us/step - loss: 0.3390 - accuracy: 0.8445\n",
      "Epoch 244/1000\n",
      "227/227 [==============================] - 0s 806us/step - loss: 0.3386 - accuracy: 0.8443\n",
      "Epoch 245/1000\n",
      "227/227 [==============================] - 0s 819us/step - loss: 0.3389 - accuracy: 0.8441\n",
      "Epoch 246/1000\n",
      "227/227 [==============================] - 0s 977us/step - loss: 0.3389 - accuracy: 0.8446\n",
      "Epoch 247/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3384 - accuracy: 0.8450\n",
      "Epoch 248/1000\n",
      "227/227 [==============================] - 0s 760us/step - loss: 0.3387 - accuracy: 0.8445\n",
      "Epoch 249/1000\n",
      "227/227 [==============================] - 0s 691us/step - loss: 0.3383 - accuracy: 0.8455\n",
      "Epoch 250/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8447\n",
      "Epoch 251/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.8441\n",
      "Epoch 252/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3385 - accuracy: 0.8453\n",
      "Epoch 253/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8455\n",
      "Epoch 254/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8459\n",
      "Epoch 255/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.8459\n",
      "Epoch 256/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3387 - accuracy: 0.8456\n",
      "Epoch 257/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3381 - accuracy: 0.8448\n",
      "Epoch 258/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8459\n",
      "Epoch 259/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3380 - accuracy: 0.8440\n",
      "Epoch 260/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8446\n",
      "Epoch 261/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8454\n",
      "Epoch 262/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8446\n",
      "Epoch 263/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8455\n",
      "Epoch 264/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8436\n",
      "Epoch 265/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8450\n",
      "Epoch 266/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8442\n",
      "Epoch 267/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8459\n",
      "Epoch 268/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3378 - accuracy: 0.8451\n",
      "Epoch 269/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3379 - accuracy: 0.8451\n",
      "Epoch 270/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8456\n",
      "Epoch 271/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8451\n",
      "Epoch 272/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3378 - accuracy: 0.8446\n",
      "Epoch 273/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3372 - accuracy: 0.8464\n",
      "Epoch 274/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.8461\n",
      "Epoch 275/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8456\n",
      "Epoch 276/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3368 - accuracy: 0.8442\n",
      "Epoch 277/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8455\n",
      "Epoch 278/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8451\n",
      "Epoch 279/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3375 - accuracy: 0.8450\n",
      "Epoch 280/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3386 - accuracy: 0.8451\n",
      "Epoch 281/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8464\n",
      "Epoch 282/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.8470\n",
      "Epoch 283/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8462\n",
      "Epoch 284/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8458\n",
      "Epoch 285/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3374 - accuracy: 0.8451\n",
      "Epoch 286/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8463\n",
      "Epoch 287/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8465\n",
      "Epoch 288/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8473\n",
      "Epoch 289/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8455\n",
      "Epoch 290/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3369 - accuracy: 0.8466\n",
      "Epoch 291/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8462\n",
      "Epoch 292/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8459\n",
      "Epoch 293/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8465\n",
      "Epoch 294/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3370 - accuracy: 0.8459\n",
      "Epoch 295/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8463\n",
      "Epoch 296/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8468\n",
      "Epoch 297/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3363 - accuracy: 0.8461\n",
      "Epoch 298/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8455\n",
      "Epoch 299/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8461\n",
      "Epoch 300/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8466\n",
      "Epoch 301/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3365 - accuracy: 0.8462\n",
      "Epoch 302/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8468\n",
      "Epoch 303/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8456\n",
      "Epoch 304/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8461\n",
      "Epoch 305/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8463\n",
      "Epoch 306/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8470\n",
      "Epoch 307/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8466\n",
      "Epoch 308/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8462\n",
      "Epoch 309/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.8474\n",
      "Epoch 310/1000\n",
      "227/227 [==============================] - 0s 994us/step - loss: 0.3367 - accuracy: 0.8462\n",
      "Epoch 311/1000\n",
      "227/227 [==============================] - 0s 986us/step - loss: 0.3363 - accuracy: 0.8465\n",
      "Epoch 312/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8460\n",
      "Epoch 313/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8453\n",
      "Epoch 314/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3357 - accuracy: 0.8461\n",
      "Epoch 315/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8463\n",
      "Epoch 316/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8461: 0s - loss: 0.3298 - \n",
      "Epoch 317/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8470\n",
      "Epoch 318/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8469\n",
      "Epoch 319/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3358 - accuracy: 0.8480\n",
      "Epoch 320/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.8462\n",
      "Epoch 321/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8461\n",
      "Epoch 322/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8471\n",
      "Epoch 323/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.8452\n",
      "Epoch 324/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8469\n",
      "Epoch 325/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8480\n",
      "Epoch 326/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8469\n",
      "Epoch 327/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8468\n",
      "Epoch 328/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8474\n",
      "Epoch 329/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8459\n",
      "Epoch 330/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8471\n",
      "Epoch 331/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8467\n",
      "Epoch 332/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8467\n",
      "Epoch 333/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8460\n",
      "Epoch 334/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8475\n",
      "Epoch 335/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8476\n",
      "Epoch 336/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8474\n",
      "Epoch 337/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8471\n",
      "Epoch 338/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3352 - accuracy: 0.8467\n",
      "Epoch 339/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8469\n",
      "Epoch 340/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8463\n",
      "Epoch 341/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8481\n",
      "Epoch 342/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8477\n",
      "Epoch 343/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8467\n",
      "Epoch 344/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8467\n",
      "Epoch 345/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8470\n",
      "Epoch 346/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3353 - accuracy: 0.8469\n",
      "Epoch 347/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3344 - accuracy: 0.8466\n",
      "Epoch 348/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3351 - accuracy: 0.8473\n",
      "Epoch 349/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8477\n",
      "Epoch 350/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8480\n",
      "Epoch 351/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8470\n",
      "Epoch 352/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8476\n",
      "Epoch 353/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8473\n",
      "Epoch 354/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8481\n",
      "Epoch 355/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8464\n",
      "Epoch 356/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8464\n",
      "Epoch 357/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8477\n",
      "Epoch 358/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8479\n",
      "Epoch 359/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8466\n",
      "Epoch 360/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8484\n",
      "Epoch 361/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8471\n",
      "Epoch 362/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8487\n",
      "Epoch 363/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8480\n",
      "Epoch 364/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8478\n",
      "Epoch 365/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8483\n",
      "Epoch 366/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8468\n",
      "Epoch 367/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8462\n",
      "Epoch 368/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8471\n",
      "Epoch 369/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8463\n",
      "Epoch 370/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8480\n",
      "Epoch 371/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8478\n",
      "Epoch 372/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8469\n",
      "Epoch 373/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8479\n",
      "Epoch 374/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8482\n",
      "Epoch 375/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8471\n",
      "Epoch 376/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8479\n",
      "Epoch 377/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8477\n",
      "Epoch 378/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8469\n",
      "Epoch 379/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3338 - accuracy: 0.8471\n",
      "Epoch 380/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8470\n",
      "Epoch 381/1000\n",
      "227/227 [==============================] - 0s 997us/step - loss: 0.3335 - accuracy: 0.8472\n",
      "Epoch 382/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3342 - accuracy: 0.8485\n",
      "Epoch 383/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8481\n",
      "Epoch 384/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8486\n",
      "Epoch 385/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8492\n",
      "Epoch 386/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8469\n",
      "Epoch 387/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3331 - accuracy: 0.8475\n",
      "Epoch 388/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8481\n",
      "Epoch 389/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3334 - accuracy: 0.8469\n",
      "Epoch 390/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8484\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8481\n",
      "Epoch 392/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8484\n",
      "Epoch 393/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8478\n",
      "Epoch 394/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8482\n",
      "Epoch 395/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8477\n",
      "Epoch 396/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8468\n",
      "Epoch 397/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8473\n",
      "Epoch 398/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8479\n",
      "Epoch 399/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8479\n",
      "Epoch 400/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8480\n",
      "Epoch 401/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3330 - accuracy: 0.8474\n",
      "Epoch 402/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3336 - accuracy: 0.8486\n",
      "Epoch 403/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3334 - accuracy: 0.8471\n",
      "Epoch 404/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3330 - accuracy: 0.8474\n",
      "Epoch 405/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8487\n",
      "Epoch 406/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8476\n",
      "Epoch 407/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8478\n",
      "Epoch 408/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8480\n",
      "Epoch 409/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8471\n",
      "Epoch 410/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8482\n",
      "Epoch 411/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8475\n",
      "Epoch 412/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8490\n",
      "Epoch 413/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8485\n",
      "Epoch 414/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8485\n",
      "Epoch 415/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8485\n",
      "Epoch 416/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8495\n",
      "Epoch 417/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8481\n",
      "Epoch 418/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3323 - accuracy: 0.8481\n",
      "Epoch 419/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8487: 0s - loss: 0.3287 - accura\n",
      "Epoch 420/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8474\n",
      "Epoch 421/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8480\n",
      "Epoch 422/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8480\n",
      "Epoch 423/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8472\n",
      "Epoch 424/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3324 - accuracy: 0.8486\n",
      "Epoch 425/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8479\n",
      "Epoch 426/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8485\n",
      "Epoch 427/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8486\n",
      "Epoch 428/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8488\n",
      "Epoch 429/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8475\n",
      "Epoch 430/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8471\n",
      "Epoch 431/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8473\n",
      "Epoch 432/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8482\n",
      "Epoch 433/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8487\n",
      "Epoch 434/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8493\n",
      "Epoch 435/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8472\n",
      "Epoch 436/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8482\n",
      "Epoch 437/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8485\n",
      "Epoch 438/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8485\n",
      "Epoch 439/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8493\n",
      "Epoch 440/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8496\n",
      "Epoch 441/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8499\n",
      "Epoch 442/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8471: 0s - loss: 0.3240 - accura\n",
      "Epoch 443/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8485\n",
      "Epoch 444/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8490\n",
      "Epoch 445/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8478\n",
      "Epoch 446/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8485\n",
      "Epoch 447/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8491\n",
      "Epoch 448/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8492\n",
      "Epoch 449/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8482\n",
      "Epoch 450/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8489\n",
      "Epoch 451/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8481\n",
      "Epoch 452/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8484\n",
      "Epoch 453/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8484\n",
      "Epoch 454/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8482\n",
      "Epoch 455/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8482\n",
      "Epoch 456/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8466\n",
      "Epoch 457/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8489\n",
      "Epoch 458/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8481\n",
      "Epoch 459/1000\n",
      "227/227 [==============================] - 0s 933us/step - loss: 0.3314 - accuracy: 0.8495\n",
      "Epoch 460/1000\n",
      "227/227 [==============================] - 0s 925us/step - loss: 0.3310 - accuracy: 0.8492\n",
      "Epoch 461/1000\n",
      "227/227 [==============================] - 0s 911us/step - loss: 0.3314 - accuracy: 0.8491\n",
      "Epoch 462/1000\n",
      "227/227 [==============================] - 0s 903us/step - loss: 0.3320 - accuracy: 0.8495\n",
      "Epoch 463/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3326 - accuracy: 0.8479\n",
      "Epoch 464/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8474\n",
      "Epoch 465/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8490\n",
      "Epoch 466/1000\n",
      "227/227 [==============================] - 0s 938us/step - loss: 0.3317 - accuracy: 0.8489\n",
      "Epoch 467/1000\n",
      "227/227 [==============================] - 0s 933us/step - loss: 0.3311 - accuracy: 0.8484\n",
      "Epoch 468/1000\n",
      "227/227 [==============================] - 0s 889us/step - loss: 0.3321 - accuracy: 0.8488\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 911us/step - loss: 0.3325 - accuracy: 0.8476\n",
      "Epoch 470/1000\n",
      "227/227 [==============================] - 0s 841us/step - loss: 0.3312 - accuracy: 0.8493\n",
      "Epoch 471/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3318 - accuracy: 0.8485\n",
      "Epoch 472/1000\n",
      "227/227 [==============================] - 0s 876us/step - loss: 0.3312 - accuracy: 0.8496\n",
      "Epoch 473/1000\n",
      "227/227 [==============================] - 0s 977us/step - loss: 0.3321 - accuracy: 0.8487\n",
      "Epoch 474/1000\n",
      "227/227 [==============================] - 0s 845us/step - loss: 0.3317 - accuracy: 0.8486\n",
      "Epoch 475/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3314 - accuracy: 0.8485\n",
      "Epoch 476/1000\n",
      "227/227 [==============================] - 0s 889us/step - loss: 0.3312 - accuracy: 0.8484\n",
      "Epoch 477/1000\n",
      "227/227 [==============================] - 0s 889us/step - loss: 0.3324 - accuracy: 0.8476\n",
      "Epoch 478/1000\n",
      "227/227 [==============================] - 0s 920us/step - loss: 0.3311 - accuracy: 0.8489\n",
      "Epoch 479/1000\n",
      "227/227 [==============================] - 0s 907us/step - loss: 0.3315 - accuracy: 0.8490\n",
      "Epoch 480/1000\n",
      "227/227 [==============================] - 0s 964us/step - loss: 0.3310 - accuracy: 0.8484\n",
      "Epoch 481/1000\n",
      "227/227 [==============================] - 0s 857us/step - loss: 0.3313 - accuracy: 0.8478\n",
      "Epoch 482/1000\n",
      "227/227 [==============================] - 0s 859us/step - loss: 0.3317 - accuracy: 0.8496\n",
      "Epoch 483/1000\n",
      "227/227 [==============================] - 0s 839us/step - loss: 0.3317 - accuracy: 0.8483\n",
      "Epoch 484/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8476\n",
      "Epoch 485/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8490\n",
      "Epoch 486/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8489\n",
      "Epoch 487/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8488\n",
      "Epoch 488/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.8490\n",
      "Epoch 489/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8489\n",
      "Epoch 490/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8488\n",
      "Epoch 491/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8492\n",
      "Epoch 492/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8488\n",
      "Epoch 493/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8494\n",
      "Epoch 494/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8480\n",
      "Epoch 495/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8484\n",
      "Epoch 496/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8493\n",
      "Epoch 497/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3320 - accuracy: 0.8488\n",
      "Epoch 498/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8490\n",
      "Epoch 499/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8488\n",
      "Epoch 500/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3321 - accuracy: 0.8491\n",
      "Epoch 501/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8495\n",
      "Epoch 502/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8490\n",
      "Epoch 503/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8493\n",
      "Epoch 504/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8500\n",
      "Epoch 505/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3313 - accuracy: 0.8492\n",
      "Epoch 506/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8492\n",
      "Epoch 507/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8498\n",
      "Epoch 508/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3307 - accuracy: 0.8496\n",
      "Epoch 509/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8487\n",
      "Epoch 510/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8491\n",
      "Epoch 511/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8492\n",
      "Epoch 512/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8496\n",
      "Epoch 513/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8497\n",
      "Epoch 514/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8478\n",
      "Epoch 515/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8489\n",
      "Epoch 516/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8504\n",
      "Epoch 517/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8497\n",
      "Epoch 518/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8485\n",
      "Epoch 519/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8491\n",
      "Epoch 520/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8498\n",
      "Epoch 521/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3311 - accuracy: 0.8493\n",
      "Epoch 522/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8489\n",
      "Epoch 523/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8505\n",
      "Epoch 524/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8495\n",
      "Epoch 525/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3312 - accuracy: 0.8481\n",
      "Epoch 526/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8479\n",
      "Epoch 527/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8498\n",
      "Epoch 528/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3319 - accuracy: 0.8476\n",
      "Epoch 529/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8500\n",
      "Epoch 530/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8484\n",
      "Epoch 531/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8493\n",
      "Epoch 532/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8487\n",
      "Epoch 533/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8500\n",
      "Epoch 534/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3315 - accuracy: 0.8489\n",
      "Epoch 535/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8498\n",
      "Epoch 536/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3307 - accuracy: 0.8488\n",
      "Epoch 537/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3304 - accuracy: 0.8493\n",
      "Epoch 538/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8484\n",
      "Epoch 539/1000\n",
      "227/227 [==============================] - 0s 993us/step - loss: 0.3304 - accuracy: 0.8493\n",
      "Epoch 540/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8493\n",
      "Epoch 541/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8494\n",
      "Epoch 542/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8496\n",
      "Epoch 543/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8497\n",
      "Epoch 544/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8488\n",
      "Epoch 545/1000\n",
      "227/227 [==============================] - 0s 986us/step - loss: 0.3303 - accuracy: 0.8494\n",
      "Epoch 546/1000\n",
      "227/227 [==============================] - 0s 898us/step - loss: 0.3304 - accuracy: 0.8487\n",
      "Epoch 547/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8475\n",
      "Epoch 548/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8492\n",
      "Epoch 549/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3300 - accuracy: 0.8499\n",
      "Epoch 550/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8493\n",
      "Epoch 551/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8495\n",
      "Epoch 552/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3308 - accuracy: 0.8488\n",
      "Epoch 553/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8485\n",
      "Epoch 554/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8502\n",
      "Epoch 555/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8489\n",
      "Epoch 556/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8490\n",
      "Epoch 557/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3305 - accuracy: 0.8487\n",
      "Epoch 558/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.8495\n",
      "Epoch 559/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8485\n",
      "Epoch 560/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8488\n",
      "Epoch 561/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8489\n",
      "Epoch 562/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8486\n",
      "Epoch 563/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8489\n",
      "Epoch 564/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8502\n",
      "Epoch 565/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8488\n",
      "Epoch 566/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8494\n",
      "Epoch 567/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8492\n",
      "Epoch 568/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8490\n",
      "Epoch 569/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8497\n",
      "Epoch 570/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8496\n",
      "Epoch 571/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8503\n",
      "Epoch 572/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8500\n",
      "Epoch 573/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3302 - accuracy: 0.8494\n",
      "Epoch 574/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3308 - accuracy: 0.8495\n",
      "Epoch 575/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8494\n",
      "Epoch 576/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8489\n",
      "Epoch 577/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8497\n",
      "Epoch 578/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8497\n",
      "Epoch 579/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8503\n",
      "Epoch 580/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8485\n",
      "Epoch 581/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8500\n",
      "Epoch 582/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8495\n",
      "Epoch 583/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8497\n",
      "Epoch 584/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8493\n",
      "Epoch 585/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8496\n",
      "Epoch 586/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8499\n",
      "Epoch 587/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8496\n",
      "Epoch 588/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3305 - accuracy: 0.8491\n",
      "Epoch 589/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8496\n",
      "Epoch 590/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.8491\n",
      "Epoch 591/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3297 - accuracy: 0.8499\n",
      "Epoch 592/1000\n",
      "227/227 [==============================] - 0s 954us/step - loss: 0.3301 - accuracy: 0.8489\n",
      "Epoch 593/1000\n",
      "227/227 [==============================] - 0s 907us/step - loss: 0.3302 - accuracy: 0.8492\n",
      "Epoch 594/1000\n",
      "227/227 [==============================] - 0s 914us/step - loss: 0.3303 - accuracy: 0.8490\n",
      "Epoch 595/1000\n",
      "227/227 [==============================] - 0s 969us/step - loss: 0.3303 - accuracy: 0.8486\n",
      "Epoch 596/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8505\n",
      "Epoch 597/1000\n",
      "227/227 [==============================] - 1s 4ms/step - loss: 0.3303 - accuracy: 0.8495\n",
      "Epoch 598/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3301 - accuracy: 0.8498\n",
      "Epoch 599/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8499\n",
      "Epoch 600/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8491\n",
      "Epoch 601/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8482\n",
      "Epoch 602/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8497\n",
      "Epoch 603/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3309 - accuracy: 0.8488\n",
      "Epoch 604/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8501\n",
      "Epoch 605/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8493\n",
      "Epoch 606/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8488\n",
      "Epoch 607/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8500\n",
      "Epoch 608/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8500\n",
      "Epoch 609/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8494\n",
      "Epoch 610/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8506\n",
      "Epoch 611/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8493\n",
      "Epoch 612/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8504\n",
      "Epoch 613/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8491\n",
      "Epoch 614/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8488\n",
      "Epoch 615/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8494\n",
      "Epoch 616/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8490\n",
      "Epoch 617/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8501\n",
      "Epoch 618/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8481\n",
      "Epoch 619/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8504\n",
      "Epoch 620/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8507\n",
      "Epoch 621/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3303 - accuracy: 0.8500\n",
      "Epoch 622/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8495\n",
      "Epoch 623/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8474\n",
      "Epoch 624/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8495\n",
      "Epoch 625/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8503\n",
      "Epoch 626/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8481\n",
      "Epoch 627/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3303 - accuracy: 0.8492\n",
      "Epoch 628/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8503\n",
      "Epoch 629/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8487\n",
      "Epoch 630/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8501\n",
      "Epoch 631/1000\n",
      "227/227 [==============================] - 0s 903us/step - loss: 0.3298 - accuracy: 0.8486\n",
      "Epoch 632/1000\n",
      "227/227 [==============================] - 0s 929us/step - loss: 0.3303 - accuracy: 0.8492\n",
      "Epoch 633/1000\n",
      "227/227 [==============================] - 0s 911us/step - loss: 0.3291 - accuracy: 0.8499\n",
      "Epoch 634/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8493\n",
      "Epoch 635/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8488\n",
      "Epoch 636/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3298 - accuracy: 0.8503\n",
      "Epoch 637/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8490\n",
      "Epoch 638/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8487\n",
      "Epoch 639/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8500\n",
      "Epoch 640/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8497\n",
      "Epoch 641/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8491\n",
      "Epoch 642/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8481\n",
      "Epoch 643/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3306 - accuracy: 0.8491\n",
      "Epoch 644/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8488\n",
      "Epoch 645/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8502\n",
      "Epoch 646/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8499\n",
      "Epoch 647/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8504\n",
      "Epoch 648/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3302 - accuracy: 0.8488\n",
      "Epoch 649/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8485\n",
      "Epoch 650/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8489\n",
      "Epoch 651/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3307 - accuracy: 0.8501\n",
      "Epoch 652/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3300 - accuracy: 0.8493\n",
      "Epoch 653/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3317 - accuracy: 0.8488\n",
      "Epoch 654/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8494\n",
      "Epoch 655/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8498\n",
      "Epoch 656/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8491\n",
      "Epoch 657/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8496\n",
      "Epoch 658/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8491\n",
      "Epoch 659/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8488\n",
      "Epoch 660/1000\n",
      "227/227 [==============================] - 0s 905us/step - loss: 0.3291 - accuracy: 0.8477\n",
      "Epoch 661/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8499\n",
      "Epoch 662/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3296 - accuracy: 0.8490\n",
      "Epoch 663/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8508\n",
      "Epoch 664/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8493\n",
      "Epoch 665/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.8489\n",
      "Epoch 666/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3295 - accuracy: 0.8485: 0s - loss: 0.3308 - accura\n",
      "Epoch 667/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8499\n",
      "Epoch 668/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8477\n",
      "Epoch 669/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8491\n",
      "Epoch 670/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8511\n",
      "Epoch 671/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8484\n",
      "Epoch 672/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8496\n",
      "Epoch 673/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.8493\n",
      "Epoch 674/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8485\n",
      "Epoch 675/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8478\n",
      "Epoch 676/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8494\n",
      "Epoch 677/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8493\n",
      "Epoch 678/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8506\n",
      "Epoch 679/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8501\n",
      "Epoch 680/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8491\n",
      "Epoch 681/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8496\n",
      "Epoch 682/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3301 - accuracy: 0.8486\n",
      "Epoch 683/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8486\n",
      "Epoch 684/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8495\n",
      "Epoch 685/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8500\n",
      "Epoch 686/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8496\n",
      "Epoch 687/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8501\n",
      "Epoch 688/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3294 - accuracy: 0.8503\n",
      "Epoch 689/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8498\n",
      "Epoch 690/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8496\n",
      "Epoch 691/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3305 - accuracy: 0.8491\n",
      "Epoch 692/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8497\n",
      "Epoch 693/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8498\n",
      "Epoch 694/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8488\n",
      "Epoch 695/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8491\n",
      "Epoch 696/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8482\n",
      "Epoch 697/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8486\n",
      "Epoch 698/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8499\n",
      "Epoch 699/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8493\n",
      "Epoch 700/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3287 - accuracy: 0.8493\n",
      "Epoch 701/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8500\n",
      "Epoch 702/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8489\n",
      "Epoch 703/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8516\n",
      "Epoch 704/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8488\n",
      "Epoch 705/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8493\n",
      "Epoch 706/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8485\n",
      "Epoch 707/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8494\n",
      "Epoch 708/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8497\n",
      "Epoch 709/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8492\n",
      "Epoch 710/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8489\n",
      "Epoch 711/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8497\n",
      "Epoch 712/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3290 - accuracy: 0.8488\n",
      "Epoch 713/1000\n",
      "227/227 [==============================] - 0s 911us/step - loss: 0.3290 - accuracy: 0.8484\n",
      "Epoch 714/1000\n",
      "227/227 [==============================] - 0s 933us/step - loss: 0.3292 - accuracy: 0.8508\n",
      "Epoch 715/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.8484\n",
      "Epoch 716/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3293 - accuracy: 0.8497\n",
      "Epoch 717/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8491\n",
      "Epoch 718/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3295 - accuracy: 0.8488\n",
      "Epoch 719/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8482\n",
      "Epoch 720/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3290 - accuracy: 0.8504\n",
      "Epoch 721/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8487\n",
      "Epoch 722/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3298 - accuracy: 0.8497\n",
      "Epoch 723/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8500\n",
      "Epoch 724/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8505\n",
      "Epoch 725/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8493\n",
      "Epoch 726/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8492\n",
      "Epoch 727/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8498\n",
      "Epoch 728/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8489\n",
      "Epoch 729/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3295 - accuracy: 0.8493\n",
      "Epoch 730/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8491\n",
      "Epoch 731/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8489\n",
      "Epoch 732/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8507\n",
      "Epoch 733/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3296 - accuracy: 0.8488\n",
      "Epoch 734/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8487\n",
      "Epoch 735/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8486\n",
      "Epoch 736/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8490\n",
      "Epoch 737/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8509\n",
      "Epoch 738/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8490\n",
      "Epoch 739/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3284 - accuracy: 0.8481\n",
      "Epoch 740/1000\n",
      "227/227 [==============================] - 0s 957us/step - loss: 0.3295 - accuracy: 0.8493\n",
      "Epoch 741/1000\n",
      "227/227 [==============================] - 0s 978us/step - loss: 0.3283 - accuracy: 0.8481\n",
      "Epoch 742/1000\n",
      "227/227 [==============================] - 0s 942us/step - loss: 0.3285 - accuracy: 0.8495\n",
      "Epoch 743/1000\n",
      "227/227 [==============================] - 0s 960us/step - loss: 0.3285 - accuracy: 0.8494\n",
      "Epoch 744/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8500\n",
      "Epoch 745/1000\n",
      "227/227 [==============================] - 0s 925us/step - loss: 0.3283 - accuracy: 0.8494\n",
      "Epoch 746/1000\n",
      "227/227 [==============================] - 0s 983us/step - loss: 0.3289 - accuracy: 0.8481\n",
      "Epoch 747/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8493\n",
      "Epoch 748/1000\n",
      "227/227 [==============================] - 0s 992us/step - loss: 0.3284 - accuracy: 0.8504\n",
      "Epoch 749/1000\n",
      "227/227 [==============================] - 0s 921us/step - loss: 0.3285 - accuracy: 0.8507\n",
      "Epoch 750/1000\n",
      "227/227 [==============================] - 0s 880us/step - loss: 0.3287 - accuracy: 0.8499\n",
      "Epoch 751/1000\n",
      "227/227 [==============================] - 0s 863us/step - loss: 0.3289 - accuracy: 0.8491\n",
      "Epoch 752/1000\n",
      "227/227 [==============================] - 0s 867us/step - loss: 0.3279 - accuracy: 0.8502\n",
      "Epoch 753/1000\n",
      "227/227 [==============================] - 0s 845us/step - loss: 0.3283 - accuracy: 0.8489\n",
      "Epoch 754/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8502\n",
      "Epoch 755/1000\n",
      "227/227 [==============================] - 0s 964us/step - loss: 0.3292 - accuracy: 0.8489\n",
      "Epoch 756/1000\n",
      "227/227 [==============================] - 0s 925us/step - loss: 0.3291 - accuracy: 0.8481\n",
      "Epoch 757/1000\n",
      "227/227 [==============================] - 0s 953us/step - loss: 0.3289 - accuracy: 0.8504\n",
      "Epoch 758/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8486\n",
      "Epoch 759/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8490\n",
      "Epoch 760/1000\n",
      "227/227 [==============================] - 0s 792us/step - loss: 0.3289 - accuracy: 0.8489\n",
      "Epoch 761/1000\n",
      "227/227 [==============================] - 0s 766us/step - loss: 0.3282 - accuracy: 0.8498\n",
      "Epoch 762/1000\n",
      "227/227 [==============================] - 0s 771us/step - loss: 0.3290 - accuracy: 0.8493\n",
      "Epoch 763/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3292 - accuracy: 0.8488\n",
      "Epoch 764/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8491\n",
      "Epoch 765/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.8511\n",
      "Epoch 766/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3282 - accuracy: 0.8492\n",
      "Epoch 767/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8493\n",
      "Epoch 768/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8501\n",
      "Epoch 769/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8500\n",
      "Epoch 770/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8490\n",
      "Epoch 771/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3291 - accuracy: 0.8485\n",
      "Epoch 772/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8496\n",
      "Epoch 773/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8493\n",
      "Epoch 774/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8502\n",
      "Epoch 775/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8500\n",
      "Epoch 776/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8497\n",
      "Epoch 777/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8503\n",
      "Epoch 778/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8508: 0s - loss: 0.3244 - accu\n",
      "Epoch 779/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8487\n",
      "Epoch 780/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8498\n",
      "Epoch 781/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 995us/step - loss: 0.3279 - accuracy: 0.8492\n",
      "Epoch 782/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8488\n",
      "Epoch 783/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8487: 0s - loss: 0.3174 - accura\n",
      "Epoch 784/1000\n",
      "227/227 [==============================] - 0s 986us/step - loss: 0.3284 - accuracy: 0.8502\n",
      "Epoch 785/1000\n",
      "227/227 [==============================] - 0s 986us/step - loss: 0.3281 - accuracy: 0.8494\n",
      "Epoch 786/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8504\n",
      "Epoch 787/1000\n",
      "227/227 [==============================] - 0s 954us/step - loss: 0.3285 - accuracy: 0.8488\n",
      "Epoch 788/1000\n",
      "227/227 [==============================] - 0s 907us/step - loss: 0.3285 - accuracy: 0.8497\n",
      "Epoch 789/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3285 - accuracy: 0.8490\n",
      "Epoch 790/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8500\n",
      "Epoch 791/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8492\n",
      "Epoch 792/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8495\n",
      "Epoch 793/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3288 - accuracy: 0.8489\n",
      "Epoch 794/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8505\n",
      "Epoch 795/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8504\n",
      "Epoch 796/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3287 - accuracy: 0.8494\n",
      "Epoch 797/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8499\n",
      "Epoch 798/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8493\n",
      "Epoch 799/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8509\n",
      "Epoch 800/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.8489\n",
      "Epoch 801/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8501\n",
      "Epoch 802/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8485\n",
      "Epoch 803/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8487\n",
      "Epoch 804/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8477\n",
      "Epoch 805/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8500\n",
      "Epoch 806/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.8502\n",
      "Epoch 807/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8485\n",
      "Epoch 808/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8492\n",
      "Epoch 809/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8493\n",
      "Epoch 810/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8495\n",
      "Epoch 811/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8495\n",
      "Epoch 812/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8498\n",
      "Epoch 813/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8499\n",
      "Epoch 814/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8492\n",
      "Epoch 815/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8492\n",
      "Epoch 816/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8504\n",
      "Epoch 817/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3290 - accuracy: 0.8488\n",
      "Epoch 818/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8501\n",
      "Epoch 819/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8495\n",
      "Epoch 820/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8492\n",
      "Epoch 821/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8496\n",
      "Epoch 822/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3279 - accuracy: 0.8487\n",
      "Epoch 823/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8491\n",
      "Epoch 824/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8495\n",
      "Epoch 825/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8519\n",
      "Epoch 826/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8492\n",
      "Epoch 827/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8492\n",
      "Epoch 828/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8497\n",
      "Epoch 829/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8496\n",
      "Epoch 830/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8489\n",
      "Epoch 831/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3284 - accuracy: 0.8494\n",
      "Epoch 832/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8489\n",
      "Epoch 833/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8500\n",
      "Epoch 834/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8497\n",
      "Epoch 835/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8504\n",
      "Epoch 836/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8497\n",
      "Epoch 837/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8493\n",
      "Epoch 838/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8492\n",
      "Epoch 839/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3283 - accuracy: 0.8496\n",
      "Epoch 840/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8490\n",
      "Epoch 841/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8493\n",
      "Epoch 842/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8501\n",
      "Epoch 843/1000\n",
      "227/227 [==============================] - 0s 933us/step - loss: 0.3288 - accuracy: 0.8493\n",
      "Epoch 844/1000\n",
      "227/227 [==============================] - 0s 962us/step - loss: 0.3273 - accuracy: 0.8507\n",
      "Epoch 845/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8501\n",
      "Epoch 846/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8502\n",
      "Epoch 847/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8494\n",
      "Epoch 848/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8485\n",
      "Epoch 849/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8480\n",
      "Epoch 850/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8501\n",
      "Epoch 851/1000\n",
      "227/227 [==============================] - 0s 995us/step - loss: 0.3276 - accuracy: 0.8504\n",
      "Epoch 852/1000\n",
      "227/227 [==============================] - 0s 991us/step - loss: 0.3279 - accuracy: 0.8495\n",
      "Epoch 853/1000\n",
      "227/227 [==============================] - 0s 954us/step - loss: 0.3273 - accuracy: 0.8502\n",
      "Epoch 854/1000\n",
      "227/227 [==============================] - 0s 916us/step - loss: 0.3278 - accuracy: 0.8501\n",
      "Epoch 855/1000\n",
      "227/227 [==============================] - 0s 933us/step - loss: 0.3277 - accuracy: 0.8505\n",
      "Epoch 856/1000\n",
      "227/227 [==============================] - 0s 911us/step - loss: 0.3274 - accuracy: 0.8493\n",
      "Epoch 857/1000\n",
      "227/227 [==============================] - 0s 925us/step - loss: 0.3274 - accuracy: 0.8496\n",
      "Epoch 858/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8497\n",
      "Epoch 859/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8501\n",
      "Epoch 860/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8485\n",
      "Epoch 861/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8501\n",
      "Epoch 862/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8498\n",
      "Epoch 863/1000\n",
      "227/227 [==============================] - 0s 848us/step - loss: 0.3276 - accuracy: 0.8513\n",
      "Epoch 864/1000\n",
      "227/227 [==============================] - 0s 837us/step - loss: 0.3277 - accuracy: 0.8494\n",
      "Epoch 865/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8494\n",
      "Epoch 866/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8500\n",
      "Epoch 867/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3274 - accuracy: 0.8494\n",
      "Epoch 868/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8491\n",
      "Epoch 869/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3278 - accuracy: 0.8497: 0s - loss: 0.3\n",
      "Epoch 870/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8508\n",
      "Epoch 871/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8482\n",
      "Epoch 872/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8504\n",
      "Epoch 873/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8503\n",
      "Epoch 874/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8499\n",
      "Epoch 875/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8498\n",
      "Epoch 876/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8514\n",
      "Epoch 877/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8504\n",
      "Epoch 878/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8489\n",
      "Epoch 879/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3265 - accuracy: 0.8507\n",
      "Epoch 880/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8506\n",
      "Epoch 881/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8503\n",
      "Epoch 882/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8503\n",
      "Epoch 883/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3286 - accuracy: 0.8502\n",
      "Epoch 884/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8514\n",
      "Epoch 885/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8494\n",
      "Epoch 886/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8507\n",
      "Epoch 887/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8492\n",
      "Epoch 888/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8497\n",
      "Epoch 889/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8506\n",
      "Epoch 890/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8497\n",
      "Epoch 891/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8502\n",
      "Epoch 892/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8507\n",
      "Epoch 893/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8501\n",
      "Epoch 894/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8493\n",
      "Epoch 895/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3278 - accuracy: 0.8508\n",
      "Epoch 896/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8497\n",
      "Epoch 897/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8518\n",
      "Epoch 898/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8490\n",
      "Epoch 899/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8491\n",
      "Epoch 900/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8501\n",
      "Epoch 901/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3280 - accuracy: 0.8497\n",
      "Epoch 902/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8492\n",
      "Epoch 903/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8496: 0s - loss: 0.3215 - accura\n",
      "Epoch 904/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8503\n",
      "Epoch 905/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3277 - accuracy: 0.8486\n",
      "Epoch 906/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8508\n",
      "Epoch 907/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8506\n",
      "Epoch 908/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8498\n",
      "Epoch 909/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8498\n",
      "Epoch 910/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8514\n",
      "Epoch 911/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8495\n",
      "Epoch 912/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8500\n",
      "Epoch 913/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8503\n",
      "Epoch 914/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8492\n",
      "Epoch 915/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8500\n",
      "Epoch 916/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8504\n",
      "Epoch 917/1000\n",
      "227/227 [==============================] - 0s 999us/step - loss: 0.3269 - accuracy: 0.8501\n",
      "Epoch 918/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8500\n",
      "Epoch 919/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8505\n",
      "Epoch 920/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8517\n",
      "Epoch 921/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8498\n",
      "Epoch 922/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8491\n",
      "Epoch 923/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8498\n",
      "Epoch 924/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8502\n",
      "Epoch 925/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8489\n",
      "Epoch 926/1000\n",
      "227/227 [==============================] - 0s 956us/step - loss: 0.3273 - accuracy: 0.8503\n",
      "Epoch 927/1000\n",
      "227/227 [==============================] - 0s 915us/step - loss: 0.3271 - accuracy: 0.8493\n",
      "Epoch 928/1000\n",
      "227/227 [==============================] - 0s 916us/step - loss: 0.3277 - accuracy: 0.8497\n",
      "Epoch 929/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8497\n",
      "Epoch 930/1000\n",
      "227/227 [==============================] - 1s 3ms/step - loss: 0.3272 - accuracy: 0.8498\n",
      "Epoch 931/1000\n",
      "227/227 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.85 - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8499\n",
      "Epoch 932/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8497\n",
      "Epoch 933/1000\n",
      "227/227 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8503\n",
      "Epoch 934/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8513\n",
      "Epoch 935/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8497\n",
      "Epoch 936/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8501: 0s - loss: 0.3343 - accura\n",
      "Epoch 938/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3269 - accuracy: 0.8509\n",
      "Epoch 939/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8497\n",
      "Epoch 940/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8506\n",
      "Epoch 941/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8497\n",
      "Epoch 942/1000\n",
      "227/227 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8513\n",
      "Epoch 943/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8496\n",
      "Epoch 944/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8494\n",
      "Epoch 945/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3270 - accuracy: 0.8497\n",
      "Epoch 946/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8509\n",
      "Epoch 947/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3276 - accuracy: 0.8501\n",
      "Epoch 948/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3273 - accuracy: 0.8505\n",
      "Epoch 949/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8508\n",
      "Epoch 950/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8501\n",
      "Epoch 951/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8498\n",
      "Epoch 952/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3274 - accuracy: 0.8492\n",
      "Epoch 953/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8510\n",
      "Epoch 954/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.8499\n",
      "Epoch 955/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8504\n",
      "Epoch 956/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8504\n",
      "Epoch 957/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8499\n",
      "Epoch 958/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8502\n",
      "Epoch 959/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8507\n",
      "Epoch 960/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8501\n",
      "Epoch 961/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8510\n",
      "Epoch 962/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8489\n",
      "Epoch 963/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8504\n",
      "Epoch 964/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8505\n",
      "Epoch 965/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8493\n",
      "Epoch 966/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8502\n",
      "Epoch 967/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3266 - accuracy: 0.8503\n",
      "Epoch 968/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8492\n",
      "Epoch 969/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3272 - accuracy: 0.8509\n",
      "Epoch 970/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8509\n",
      "Epoch 971/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3263 - accuracy: 0.8502\n",
      "Epoch 972/1000\n",
      "227/227 [==============================] - 0s 996us/step - loss: 0.3262 - accuracy: 0.8493\n",
      "Epoch 973/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3269 - accuracy: 0.8501\n",
      "Epoch 974/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3267 - accuracy: 0.8501\n",
      "Epoch 975/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3275 - accuracy: 0.8494\n",
      "Epoch 976/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3259 - accuracy: 0.8507\n",
      "Epoch 977/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8503\n",
      "Epoch 978/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8501\n",
      "Epoch 979/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8507\n",
      "Epoch 980/1000\n",
      "227/227 [==============================] - 0s 973us/step - loss: 0.3266 - accuracy: 0.8490\n",
      "Epoch 981/1000\n",
      "227/227 [==============================] - 0s 925us/step - loss: 0.3270 - accuracy: 0.8505\n",
      "Epoch 982/1000\n",
      "227/227 [==============================] - 0s 918us/step - loss: 0.3270 - accuracy: 0.8497\n",
      "Epoch 983/1000\n",
      "227/227 [==============================] - 0s 903us/step - loss: 0.3268 - accuracy: 0.8504\n",
      "Epoch 984/1000\n",
      "227/227 [==============================] - 0s 916us/step - loss: 0.3263 - accuracy: 0.8504\n",
      "Epoch 985/1000\n",
      "227/227 [==============================] - 0s 982us/step - loss: 0.3264 - accuracy: 0.8508\n",
      "Epoch 986/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3268 - accuracy: 0.8513\n",
      "Epoch 987/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3264 - accuracy: 0.8502\n",
      "Epoch 988/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3262 - accuracy: 0.8509\n",
      "Epoch 989/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3260 - accuracy: 0.8504\n",
      "Epoch 990/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3255 - accuracy: 0.8497\n",
      "Epoch 991/1000\n",
      "227/227 [==============================] - 0s 1ms/step - loss: 0.3258 - accuracy: 0.8504\n",
      "Epoch 992/1000\n",
      "227/227 [==============================] - 0s 977us/step - loss: 0.3256 - accuracy: 0.8497\n",
      "Epoch 993/1000\n",
      "227/227 [==============================] - 0s 749us/step - loss: 0.3265 - accuracy: 0.8503\n",
      "Epoch 994/1000\n",
      "227/227 [==============================] - 0s 810us/step - loss: 0.3262 - accuracy: 0.8497\n",
      "Epoch 995/1000\n",
      "227/227 [==============================] - 0s 762us/step - loss: 0.3260 - accuracy: 0.8503\n",
      "Epoch 996/1000\n",
      "227/227 [==============================] - 0s 872us/step - loss: 0.3261 - accuracy: 0.8501\n",
      "Epoch 997/1000\n",
      "227/227 [==============================] - 0s 806us/step - loss: 0.3260 - accuracy: 0.8497\n",
      "Epoch 998/1000\n",
      "227/227 [==============================] - 0s 830us/step - loss: 0.3259 - accuracy: 0.8504\n",
      "Epoch 999/1000\n",
      "227/227 [==============================] - 0s 828us/step - loss: 0.3258 - accuracy: 0.8510\n",
      "Epoch 1000/1000\n",
      "227/227 [==============================] - 0s 819us/step - loss: 0.3260 - accuracy: 0.8504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a07a89f508>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# 딥러닝 구조를 결정합니다(모델을 설정하고 실행하는 부분입니다).\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=11, activation='relu'))\n",
    "model.add(Dense(12,  activation='relu'))\n",
    "model.add(Dense(8,  activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 딥러닝을 실행합니다.\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_callback=EarlyStopping(monitor='val_loss',patience=10)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=100)\n",
    "\n",
    "# print('\\n Accuracy: %.4f' %(model.evaluate(X_test,y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>모델</th>\n",
       "      <th>정확도</th>\n",
       "      <th>정밀도</th>\n",
       "      <th>재현율</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>딥러닝</td>\n",
       "      <td>0.8504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.7737</td>\n",
       "      <td>0.5662</td>\n",
       "      <td>0.6539</td>\n",
       "      <td>0.7552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBM</td>\n",
       "      <td>0.8472</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.7496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.8455</td>\n",
       "      <td>0.7744</td>\n",
       "      <td>0.5468</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>0.7465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ada부스트</td>\n",
       "      <td>0.8373</td>\n",
       "      <td>0.7582</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>0.6176</td>\n",
       "      <td>0.7325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>랜덤포레스트</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>0.7873</td>\n",
       "      <td>0.4769</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>0.7167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>결정트리</td>\n",
       "      <td>0.8309</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.4490</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>0.7044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.4327</td>\n",
       "      <td>0.5496</td>\n",
       "      <td>0.6924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>로지스틱회귀</td>\n",
       "      <td>0.8118</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.4795</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>0.6997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       모델     정확도    정밀도      재현율  F1 score     AUC\n",
       "0     딥러닝  0.8504     NaN     NaN       NaN     NaN\n",
       "1    LGBM  0.8488  0.7737  0.5662    0.6539  0.7552\n",
       "2     GBM  0.8472  0.7774  0.5526    0.6460  0.7496\n",
       "3     XGB  0.8455  0.7744  0.5468    0.6410  0.7465\n",
       "4  ada부스트  0.8373  0.7582  0.5210    0.6176  0.7325\n",
       "5  랜덤포레스트  0.8356  0.7873  0.4769    0.5940  0.7167\n",
       "6    결정트리  0.8309  0.7900  0.4490    0.5726  0.7044\n",
       "7     svm  0.8211  0.7530  0.4327    0.5496  0.6924\n",
       "8  로지스틱회귀  0.8118  0.7102  0.4290    0.5349  0.6850\n",
       "9     knn  0.8088  0.6686  0.4795    0.5585  0.6997"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=pd.read_csv('4.csv')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
